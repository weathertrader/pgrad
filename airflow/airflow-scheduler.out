[[34m2020-10-02 14:04:11,193[0m] {[34mscheduler_job.py:[0m1367} INFO[0m - Starting the scheduler[0m
[[34m2020-10-02 14:04:11,193[0m] {[34mscheduler_job.py:[0m1375} INFO[0m - Running execute loop for -1 seconds[0m
[[34m2020-10-02 14:04:11,194[0m] {[34mscheduler_job.py:[0m1376} INFO[0m - Processing each file at most -1 times[0m
[[34m2020-10-02 14:04:11,194[0m] {[34mscheduler_job.py:[0m1379} INFO[0m - Searching for files in [01m/home/csmith/pgrad/airflow/dags[22m[0m
[[34m2020-10-02 14:04:11,195[0m] {[34mscheduler_job.py:[0m1381} INFO[0m - There are 1 files in [01m/home/csmith/pgrad/airflow/dags[22m[0m
[[34m2020-10-02 14:04:11,195[0m] {[34mscheduler_job.py:[0m1438} INFO[0m - Resetting orphaned tasks for active dag runs[0m
[[34m2020-10-02 14:04:11,212[0m] {[34mdag_processing.py:[0m562} INFO[0m - Launched DagFileProcessorManager with pid: 29609[0m
[[34m2020-10-02 14:04:11,215[0m] {[34msettings.py:[0m55} INFO[0m - Configured default timezone <Timezone [UTC]>[0m
[2020-10-02 14:04:11,224] {dag_processing.py:776} WARNING - Because we cannot use more than 1 thread (max_threads = 2) when using sqlite. So we set parallelism to 1.
[[34m2020-10-02 14:04:43,265[0m] {[34mscheduler_job.py:[0m963} INFO[0m - 3 tasks up for execution:
	[01m<TaskInstance: id_01.id_cleanup 2020-10-02 19:05:00+00:00 [scheduled]>
	<TaskInstance: id_11.id_download_hrrr 2020-10-02 19:06:00+00:00 [scheduled]>
	<TaskInstance: id_21.id_download_nam 2020-10-02 19:09:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 14:04:43,271[0m] {[34mscheduler_job.py:[0m997} INFO[0m - Figuring out tasks to run in Pool(name=[01mdefault_pool[22m) with 128 open slots and 3 task instances ready to be queued[0m
[[34m2020-10-02 14:04:43,271[0m] {[34mscheduler_job.py:[0m1025} INFO[0m - DAG [01mid_11[22m has 0/16 running and queued tasks[0m
[[34m2020-10-02 14:04:43,271[0m] {[34mscheduler_job.py:[0m1025} INFO[0m - DAG [01mid_21[22m has 0/16 running and queued tasks[0m
[[34m2020-10-02 14:04:43,272[0m] {[34mscheduler_job.py:[0m1025} INFO[0m - DAG [01mid_01[22m has 0/16 running and queued tasks[0m
[[34m2020-10-02 14:04:43,276[0m] {[34mscheduler_job.py:[0m1085} INFO[0m - Setting the following tasks to queued state:
	[01m<TaskInstance: id_11.id_download_hrrr 2020-10-02 19:06:00+00:00 [scheduled]>
	<TaskInstance: id_21.id_download_nam 2020-10-02 19:09:00+00:00 [scheduled]>
	<TaskInstance: id_01.id_cleanup 2020-10-02 19:05:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 14:04:43,312[0m] {[34mscheduler_job.py:[0m1159} INFO[0m - Setting the following 3 tasks to queued state:
	[01m<TaskInstance: id_01.id_cleanup 2020-10-02 19:05:00+00:00 [queued]>
	<TaskInstance: id_11.id_download_hrrr 2020-10-02 19:06:00+00:00 [queued]>
	<TaskInstance: id_21.id_download_nam 2020-10-02 19:09:00+00:00 [queued]>[22m[0m
[[34m2020-10-02 14:04:43,313[0m] {[34mscheduler_job.py:[0m1195} INFO[0m - Sending [01m('id_01', 'id_cleanup', datetime.datetime(2020, 10, 2, 19, 5, tzinfo=<Timezone [UTC]>), 1)[22m to executor with priority 1 and queue [01mdefault[22m[0m
[[34m2020-10-02 14:04:43,313[0m] {[34mbase_executor.py:[0m58} INFO[0m - Adding to queue: [01m['airflow', 'run', 'id_01', 'id_cleanup', '2020-10-02T19:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[[34m2020-10-02 14:04:43,313[0m] {[34mscheduler_job.py:[0m1195} INFO[0m - Sending [01m('id_11', 'id_download_hrrr', datetime.datetime(2020, 10, 2, 19, 6, tzinfo=<Timezone [UTC]>), 1)[22m to executor with priority 4 and queue [01mdefault[22m[0m
[[34m2020-10-02 14:04:43,313[0m] {[34mbase_executor.py:[0m58} INFO[0m - Adding to queue: [01m['airflow', 'run', 'id_11', 'id_download_hrrr', '2020-10-02T19:06:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[[34m2020-10-02 14:04:43,313[0m] {[34mscheduler_job.py:[0m1195} INFO[0m - Sending [01m('id_21', 'id_download_nam', datetime.datetime(2020, 10, 2, 19, 9, tzinfo=<Timezone [UTC]>), 1)[22m to executor with priority 4 and queue [01mdefault[22m[0m
[[34m2020-10-02 14:04:43,314[0m] {[34mbase_executor.py:[0m58} INFO[0m - Adding to queue: [01m['airflow', 'run', 'id_21', 'id_download_nam', '2020-10-02T19:09:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[[34m2020-10-02 14:04:43,314[0m] {[34msequential_executor.py:[0m54} INFO[0m - Executing command: [01m['airflow', 'run', 'id_11', 'id_download_hrrr', '2020-10-02T19:06:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[2020-10-02 14:04:44,682] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-10-02 14:04:44,682] {dagbag.py:417} INFO - Filling up the DagBag from /home/csmith/pgrad/airflow/dags/pgrad_dag.py
Running %s on host %s <TaskInstance: id_11.id_download_hrrr 2020-10-02T19:06:00+00:00 [queued]> penguin
[[34m2020-10-02 14:04:49,948[0m] {[34msequential_executor.py:[0m54} INFO[0m - Executing command: [01m['airflow', 'run', 'id_21', 'id_download_nam', '2020-10-02T19:09:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[2020-10-02 14:04:51,314] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-10-02 14:04:51,314] {dagbag.py:417} INFO - Filling up the DagBag from /home/csmith/pgrad/airflow/dags/pgrad_dag.py
Running %s on host %s <TaskInstance: id_21.id_download_nam 2020-10-02T19:09:00+00:00 [queued]> penguin
[[34m2020-10-02 14:05:21,802[0m] {[34msequential_executor.py:[0m54} INFO[0m - Executing command: [01m['airflow', 'run', 'id_01', 'id_cleanup', '2020-10-02T19:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[2020-10-02 14:05:23,291] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-10-02 14:05:23,292] {dagbag.py:417} INFO - Filling up the DagBag from /home/csmith/pgrad/airflow/dags/pgrad_dag.py
Running %s on host %s <TaskInstance: id_01.id_cleanup 2020-10-02T19:05:00+00:00 [queued]> penguin
[[34m2020-10-02 14:05:28,701[0m] {[34mscheduler_job.py:[0m1334} INFO[0m - Executor reports execution of [01mid_11[22m.[01mid_download_hrrr[22m execution_date=[01m2020-10-02 19:06:00+00:00[22m exited with status [01msuccess[22m for try_number 1[0m
[[34m2020-10-02 14:05:28,709[0m] {[34mscheduler_job.py:[0m1334} INFO[0m - Executor reports execution of [01mid_21[22m.[01mid_download_nam[22m execution_date=[01m2020-10-02 19:09:00+00:00[22m exited with status [01msuccess[22m for try_number 1[0m
[[34m2020-10-02 14:05:28,712[0m] {[34mscheduler_job.py:[0m1334} INFO[0m - Executor reports execution of [01mid_01[22m.[01mid_cleanup[22m execution_date=[01m2020-10-02 19:05:00+00:00[22m exited with status [01msuccess[22m for try_number 1[0m
[[34m2020-10-02 14:05:29,773[0m] {[34mscheduler_job.py:[0m963} INFO[0m - 2 tasks up for execution:
	[01m<TaskInstance: id_31.id_download_gfs 2020-10-02 19:13:00+00:00 [scheduled]>
	<TaskInstance: id_56.id_plot_data 2020-10-02 19:17:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 14:05:29,779[0m] {[34mscheduler_job.py:[0m997} INFO[0m - Figuring out tasks to run in Pool(name=[01mdefault_pool[22m) with 128 open slots and 2 task instances ready to be queued[0m
[[34m2020-10-02 14:05:29,780[0m] {[34mscheduler_job.py:[0m1025} INFO[0m - DAG [01mid_31[22m has 0/16 running and queued tasks[0m
[[34m2020-10-02 14:05:29,781[0m] {[34mscheduler_job.py:[0m1025} INFO[0m - DAG [01mid_56[22m has 0/16 running and queued tasks[0m
[[34m2020-10-02 14:05:29,788[0m] {[34mscheduler_job.py:[0m1085} INFO[0m - Setting the following tasks to queued state:
	[01m<TaskInstance: id_31.id_download_gfs 2020-10-02 19:13:00+00:00 [scheduled]>
	<TaskInstance: id_56.id_plot_data 2020-10-02 19:17:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 14:05:29,828[0m] {[34mscheduler_job.py:[0m1159} INFO[0m - Setting the following 2 tasks to queued state:
	[01m<TaskInstance: id_31.id_download_gfs 2020-10-02 19:13:00+00:00 [queued]>
	<TaskInstance: id_56.id_plot_data 2020-10-02 19:17:00+00:00 [queued]>[22m[0m
[[34m2020-10-02 14:05:29,829[0m] {[34mscheduler_job.py:[0m1195} INFO[0m - Sending [01m('id_31', 'id_download_gfs', datetime.datetime(2020, 10, 2, 19, 13, tzinfo=<Timezone [UTC]>), 1)[22m to executor with priority 4 and queue [01mdefault[22m[0m
[[34m2020-10-02 14:05:29,830[0m] {[34mbase_executor.py:[0m58} INFO[0m - Adding to queue: [01m['airflow', 'run', 'id_31', 'id_download_gfs', '2020-10-02T19:13:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[[34m2020-10-02 14:05:29,830[0m] {[34mscheduler_job.py:[0m1195} INFO[0m - Sending [01m('id_56', 'id_plot_data', datetime.datetime(2020, 10, 2, 19, 17, tzinfo=<Timezone [UTC]>), 1)[22m to executor with priority 1 and queue [01mdefault[22m[0m
[[34m2020-10-02 14:05:29,830[0m] {[34mbase_executor.py:[0m58} INFO[0m - Adding to queue: [01m['airflow', 'run', 'id_56', 'id_plot_data', '2020-10-02T19:17:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[[34m2020-10-02 14:05:29,830[0m] {[34msequential_executor.py:[0m54} INFO[0m - Executing command: [01m['airflow', 'run', 'id_31', 'id_download_gfs', '2020-10-02T19:13:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[2020-10-02 14:05:31,123] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-10-02 14:05:31,123] {dagbag.py:417} INFO - Filling up the DagBag from /home/csmith/pgrad/airflow/dags/pgrad_dag.py
Running %s on host %s <TaskInstance: id_31.id_download_gfs 2020-10-02T19:13:00+00:00 [queued]> penguin
[[34m2020-10-02 14:05:36,382[0m] {[34msequential_executor.py:[0m54} INFO[0m - Executing command: [01m['airflow', 'run', 'id_56', 'id_plot_data', '2020-10-02T19:17:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[2020-10-02 14:05:37,581] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-10-02 14:05:37,581] {dagbag.py:417} INFO - Filling up the DagBag from /home/csmith/pgrad/airflow/dags/pgrad_dag.py
Running %s on host %s <TaskInstance: id_56.id_plot_data 2020-10-02T19:17:00+00:00 [queued]> penguin
[[34m2020-10-02 14:06:07,920[0m] {[34mscheduler_job.py:[0m1334} INFO[0m - Executor reports execution of [01mid_31[22m.[01mid_download_gfs[22m execution_date=[01m2020-10-02 19:13:00+00:00[22m exited with status [01msuccess[22m for try_number 1[0m
[[34m2020-10-02 14:06:07,927[0m] {[34mscheduler_job.py:[0m1334} INFO[0m - Executor reports execution of [01mid_56[22m.[01mid_plot_data[22m execution_date=[01m2020-10-02 19:17:00+00:00[22m exited with status [01msuccess[22m for try_number 1[0m
[[34m2020-10-02 14:06:08,992[0m] {[34mscheduler_job.py:[0m963} INFO[0m - 3 tasks up for execution:
	[01m<TaskInstance: id_01.id_cleanup 2020-10-02 20:05:00+00:00 [scheduled]>
	<TaskInstance: id_11.id_process_grib_hrrr 2020-10-02 19:06:00+00:00 [scheduled]>
	<TaskInstance: id_21.id_process_grib_nam 2020-10-02 19:09:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 14:06:08,997[0m] {[34mscheduler_job.py:[0m997} INFO[0m - Figuring out tasks to run in Pool(name=[01mdefault_pool[22m) with 128 open slots and 3 task instances ready to be queued[0m
[[34m2020-10-02 14:06:08,997[0m] {[34mscheduler_job.py:[0m1025} INFO[0m - DAG [01mid_11[22m has 0/16 running and queued tasks[0m
[[34m2020-10-02 14:06:08,998[0m] {[34mscheduler_job.py:[0m1025} INFO[0m - DAG [01mid_21[22m has 0/16 running and queued tasks[0m
[[34m2020-10-02 14:06:08,998[0m] {[34mscheduler_job.py:[0m1025} INFO[0m - DAG [01mid_01[22m has 0/16 running and queued tasks[0m
[[34m2020-10-02 14:06:09,003[0m] {[34mscheduler_job.py:[0m1085} INFO[0m - Setting the following tasks to queued state:
	[01m<TaskInstance: id_11.id_process_grib_hrrr 2020-10-02 19:06:00+00:00 [scheduled]>
	<TaskInstance: id_21.id_process_grib_nam 2020-10-02 19:09:00+00:00 [scheduled]>
	<TaskInstance: id_01.id_cleanup 2020-10-02 20:05:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 14:06:09,042[0m] {[34mscheduler_job.py:[0m1159} INFO[0m - Setting the following 3 tasks to queued state:
	[01m<TaskInstance: id_11.id_process_grib_hrrr 2020-10-02 19:06:00+00:00 [queued]>
	<TaskInstance: id_21.id_process_grib_nam 2020-10-02 19:09:00+00:00 [queued]>
	<TaskInstance: id_01.id_cleanup 2020-10-02 20:05:00+00:00 [queued]>[22m[0m
[[34m2020-10-02 14:06:09,042[0m] {[34mscheduler_job.py:[0m1195} INFO[0m - Sending [01m('id_11', 'id_process_grib_hrrr', datetime.datetime(2020, 10, 2, 19, 6, tzinfo=<Timezone [UTC]>), 1)[22m to executor with priority 3 and queue [01mdefault[22m[0m
[[34m2020-10-02 14:06:09,042[0m] {[34mbase_executor.py:[0m58} INFO[0m - Adding to queue: [01m['airflow', 'run', 'id_11', 'id_process_grib_hrrr', '2020-10-02T19:06:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[[34m2020-10-02 14:06:09,042[0m] {[34mscheduler_job.py:[0m1195} INFO[0m - Sending [01m('id_21', 'id_process_grib_nam', datetime.datetime(2020, 10, 2, 19, 9, tzinfo=<Timezone [UTC]>), 1)[22m to executor with priority 3 and queue [01mdefault[22m[0m
[[34m2020-10-02 14:06:09,042[0m] {[34mbase_executor.py:[0m58} INFO[0m - Adding to queue: [01m['airflow', 'run', 'id_21', 'id_process_grib_nam', '2020-10-02T19:09:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[[34m2020-10-02 14:06:09,043[0m] {[34mscheduler_job.py:[0m1195} INFO[0m - Sending [01m('id_01', 'id_cleanup', datetime.datetime(2020, 10, 2, 20, 5, tzinfo=<Timezone [UTC]>), 1)[22m to executor with priority 1 and queue [01mdefault[22m[0m
[[34m2020-10-02 14:06:09,043[0m] {[34mbase_executor.py:[0m58} INFO[0m - Adding to queue: [01m['airflow', 'run', 'id_01', 'id_cleanup', '2020-10-02T20:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[[34m2020-10-02 14:06:09,043[0m] {[34msequential_executor.py:[0m54} INFO[0m - Executing command: [01m['airflow', 'run', 'id_11', 'id_process_grib_hrrr', '2020-10-02T19:06:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[2020-10-02 14:06:10,331] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-10-02 14:06:10,332] {dagbag.py:417} INFO - Filling up the DagBag from /home/csmith/pgrad/airflow/dags/pgrad_dag.py
Running %s on host %s <TaskInstance: id_11.id_process_grib_hrrr 2020-10-02T19:06:00+00:00 [queued]> penguin
[[34m2020-10-02 14:06:15,662[0m] {[34msequential_executor.py:[0m54} INFO[0m - Executing command: [01m['airflow', 'run', 'id_21', 'id_process_grib_nam', '2020-10-02T19:09:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[2020-10-02 14:06:16,884] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-10-02 14:06:16,885] {dagbag.py:417} INFO - Filling up the DagBag from /home/csmith/pgrad/airflow/dags/pgrad_dag.py
Running %s on host %s <TaskInstance: id_21.id_process_grib_nam 2020-10-02T19:09:00+00:00 [queued]> penguin
[[34m2020-10-02 14:06:32,176[0m] {[34msequential_executor.py:[0m54} INFO[0m - Executing command: [01m['airflow', 'run', 'id_01', 'id_cleanup', '2020-10-02T20:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[2020-10-02 14:06:33,269] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-10-02 14:06:33,269] {dagbag.py:417} INFO - Filling up the DagBag from /home/csmith/pgrad/airflow/dags/pgrad_dag.py
Running %s on host %s <TaskInstance: id_01.id_cleanup 2020-10-02T20:05:00+00:00 [queued]> penguin
[[34m2020-10-02 14:06:38,600[0m] {[34mscheduler_job.py:[0m1334} INFO[0m - Executor reports execution of [01mid_11[22m.[01mid_process_grib_hrrr[22m execution_date=[01m2020-10-02 19:06:00+00:00[22m exited with status [01msuccess[22m for try_number 1[0m
[[34m2020-10-02 14:06:38,606[0m] {[34mscheduler_job.py:[0m1334} INFO[0m - Executor reports execution of [01mid_21[22m.[01mid_process_grib_nam[22m execution_date=[01m2020-10-02 19:09:00+00:00[22m exited with status [01msuccess[22m for try_number 1[0m
[[34m2020-10-02 14:06:38,608[0m] {[34mscheduler_job.py:[0m1334} INFO[0m - Executor reports execution of [01mid_01[22m.[01mid_cleanup[22m execution_date=[01m2020-10-02 20:05:00+00:00[22m exited with status [01msuccess[22m for try_number 1[0m
[[34m2020-10-02 14:06:39,664[0m] {[34mscheduler_job.py:[0m963} INFO[0m - 2 tasks up for execution:
	[01m<TaskInstance: id_11.id_download_hrrr 2020-10-02 20:06:00+00:00 [scheduled]>
	<TaskInstance: id_31.id_process_grib_gfs 2020-10-02 19:13:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 14:06:39,669[0m] {[34mscheduler_job.py:[0m997} INFO[0m - Figuring out tasks to run in Pool(name=[01mdefault_pool[22m) with 128 open slots and 2 task instances ready to be queued[0m
[[34m2020-10-02 14:06:39,669[0m] {[34mscheduler_job.py:[0m1025} INFO[0m - DAG [01mid_11[22m has 0/16 running and queued tasks[0m
[[34m2020-10-02 14:06:39,670[0m] {[34mscheduler_job.py:[0m1025} INFO[0m - DAG [01mid_31[22m has 0/16 running and queued tasks[0m
[[34m2020-10-02 14:06:39,677[0m] {[34mscheduler_job.py:[0m1085} INFO[0m - Setting the following tasks to queued state:
	[01m<TaskInstance: id_11.id_download_hrrr 2020-10-02 20:06:00+00:00 [scheduled]>
	<TaskInstance: id_31.id_process_grib_gfs 2020-10-02 19:13:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 14:06:39,709[0m] {[34mscheduler_job.py:[0m1159} INFO[0m - Setting the following 2 tasks to queued state:
	[01m<TaskInstance: id_11.id_download_hrrr 2020-10-02 20:06:00+00:00 [queued]>
	<TaskInstance: id_31.id_process_grib_gfs 2020-10-02 19:13:00+00:00 [queued]>[22m[0m
[[34m2020-10-02 14:06:39,709[0m] {[34mscheduler_job.py:[0m1195} INFO[0m - Sending [01m('id_11', 'id_download_hrrr', datetime.datetime(2020, 10, 2, 20, 6, tzinfo=<Timezone [UTC]>), 1)[22m to executor with priority 4 and queue [01mdefault[22m[0m
[[34m2020-10-02 14:06:39,710[0m] {[34mbase_executor.py:[0m58} INFO[0m - Adding to queue: [01m['airflow', 'run', 'id_11', 'id_download_hrrr', '2020-10-02T20:06:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[[34m2020-10-02 14:06:39,710[0m] {[34mscheduler_job.py:[0m1195} INFO[0m - Sending [01m('id_31', 'id_process_grib_gfs', datetime.datetime(2020, 10, 2, 19, 13, tzinfo=<Timezone [UTC]>), 1)[22m to executor with priority 3 and queue [01mdefault[22m[0m
[[34m2020-10-02 14:06:39,710[0m] {[34mbase_executor.py:[0m58} INFO[0m - Adding to queue: [01m['airflow', 'run', 'id_31', 'id_process_grib_gfs', '2020-10-02T19:13:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[[34m2020-10-02 14:06:39,710[0m] {[34msequential_executor.py:[0m54} INFO[0m - Executing command: [01m['airflow', 'run', 'id_11', 'id_download_hrrr', '2020-10-02T20:06:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[2020-10-02 14:06:41,164] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-10-02 14:06:41,164] {dagbag.py:417} INFO - Filling up the DagBag from /home/csmith/pgrad/airflow/dags/pgrad_dag.py
Running %s on host %s <TaskInstance: id_11.id_download_hrrr 2020-10-02T20:06:00+00:00 [queued]> penguin
[[34m2020-10-02 14:06:46,451[0m] {[34msequential_executor.py:[0m54} INFO[0m - Executing command: [01m['airflow', 'run', 'id_31', 'id_process_grib_gfs', '2020-10-02T19:13:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[2020-10-02 14:06:48,352] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-10-02 14:06:48,353] {dagbag.py:417} INFO - Filling up the DagBag from /home/csmith/pgrad/airflow/dags/pgrad_dag.py
Running %s on host %s <TaskInstance: id_31.id_process_grib_gfs 2020-10-02T19:13:00+00:00 [queued]> penguin
[[34m2020-10-02 14:06:53,653[0m] {[34mscheduler_job.py:[0m1334} INFO[0m - Executor reports execution of [01mid_11[22m.[01mid_download_hrrr[22m execution_date=[01m2020-10-02 20:06:00+00:00[22m exited with status [01msuccess[22m for try_number 1[0m
[[34m2020-10-02 14:06:53,658[0m] {[34mscheduler_job.py:[0m1334} INFO[0m - Executor reports execution of [01mid_31[22m.[01mid_process_grib_gfs[22m execution_date=[01m2020-10-02 19:13:00+00:00[22m exited with status [01msuccess[22m for try_number 1[0m
[[34m2020-10-02 14:06:54,716[0m] {[34mscheduler_job.py:[0m963} INFO[0m - 2 tasks up for execution:
	[01m<TaskInstance: id_11.id_process_csv_hrrr 2020-10-02 19:06:00+00:00 [scheduled]>
	<TaskInstance: id_21.id_process_csv_nam 2020-10-02 19:09:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 14:06:54,719[0m] {[34mscheduler_job.py:[0m997} INFO[0m - Figuring out tasks to run in Pool(name=[01mdefault_pool[22m) with 128 open slots and 2 task instances ready to be queued[0m
[[34m2020-10-02 14:06:54,720[0m] {[34mscheduler_job.py:[0m1025} INFO[0m - DAG [01mid_11[22m has 0/16 running and queued tasks[0m
[[34m2020-10-02 14:06:54,720[0m] {[34mscheduler_job.py:[0m1025} INFO[0m - DAG [01mid_21[22m has 0/16 running and queued tasks[0m
[[34m2020-10-02 14:06:54,725[0m] {[34mscheduler_job.py:[0m1085} INFO[0m - Setting the following tasks to queued state:
	[01m<TaskInstance: id_11.id_process_csv_hrrr 2020-10-02 19:06:00+00:00 [scheduled]>
	<TaskInstance: id_21.id_process_csv_nam 2020-10-02 19:09:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 14:06:54,763[0m] {[34mscheduler_job.py:[0m1159} INFO[0m - Setting the following 2 tasks to queued state:
	[01m<TaskInstance: id_11.id_process_csv_hrrr 2020-10-02 19:06:00+00:00 [queued]>
	<TaskInstance: id_21.id_process_csv_nam 2020-10-02 19:09:00+00:00 [queued]>[22m[0m
[[34m2020-10-02 14:06:54,764[0m] {[34mscheduler_job.py:[0m1195} INFO[0m - Sending [01m('id_11', 'id_process_csv_hrrr', datetime.datetime(2020, 10, 2, 19, 6, tzinfo=<Timezone [UTC]>), 1)[22m to executor with priority 2 and queue [01mdefault[22m[0m
[[34m2020-10-02 14:06:54,764[0m] {[34mbase_executor.py:[0m58} INFO[0m - Adding to queue: [01m['airflow', 'run', 'id_11', 'id_process_csv_hrrr', '2020-10-02T19:06:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[[34m2020-10-02 14:06:54,764[0m] {[34mscheduler_job.py:[0m1195} INFO[0m - Sending [01m('id_21', 'id_process_csv_nam', datetime.datetime(2020, 10, 2, 19, 9, tzinfo=<Timezone [UTC]>), 1)[22m to executor with priority 2 and queue [01mdefault[22m[0m
[[34m2020-10-02 14:06:54,764[0m] {[34mbase_executor.py:[0m58} INFO[0m - Adding to queue: [01m['airflow', 'run', 'id_21', 'id_process_csv_nam', '2020-10-02T19:09:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[[34m2020-10-02 14:06:54,765[0m] {[34msequential_executor.py:[0m54} INFO[0m - Executing command: [01m['airflow', 'run', 'id_11', 'id_process_csv_hrrr', '2020-10-02T19:06:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[2020-10-02 14:06:56,181] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-10-02 14:06:56,182] {dagbag.py:417} INFO - Filling up the DagBag from /home/csmith/pgrad/airflow/dags/pgrad_dag.py
Running %s on host %s <TaskInstance: id_11.id_process_csv_hrrr 2020-10-02T19:06:00+00:00 [queued]> penguin
[[34m2020-10-02 14:07:01,485[0m] {[34msequential_executor.py:[0m54} INFO[0m - Executing command: [01m['airflow', 'run', 'id_21', 'id_process_csv_nam', '2020-10-02T19:09:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[2020-10-02 14:07:02,898] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-10-02 14:07:02,898] {dagbag.py:417} INFO - Filling up the DagBag from /home/csmith/pgrad/airflow/dags/pgrad_dag.py
Running %s on host %s <TaskInstance: id_21.id_process_csv_nam 2020-10-02T19:09:00+00:00 [queued]> penguin
[[34m2020-10-02 14:07:08,163[0m] {[34mscheduler_job.py:[0m1334} INFO[0m - Executor reports execution of [01mid_11[22m.[01mid_process_csv_hrrr[22m execution_date=[01m2020-10-02 19:06:00+00:00[22m exited with status [01msuccess[22m for try_number 1[0m
[[34m2020-10-02 14:07:08,171[0m] {[34mscheduler_job.py:[0m1334} INFO[0m - Executor reports execution of [01mid_21[22m.[01mid_process_csv_nam[22m execution_date=[01m2020-10-02 19:09:00+00:00[22m exited with status [01msuccess[22m for try_number 1[0m
[[34m2020-10-02 14:07:09,233[0m] {[34mscheduler_job.py:[0m963} INFO[0m - 2 tasks up for execution:
	[01m<TaskInstance: id_11.id_process_grib_hrrr 2020-10-02 20:06:00+00:00 [scheduled]>
	<TaskInstance: id_31.id_process_csv_gfs 2020-10-02 19:13:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 14:07:09,239[0m] {[34mscheduler_job.py:[0m997} INFO[0m - Figuring out tasks to run in Pool(name=[01mdefault_pool[22m) with 128 open slots and 2 task instances ready to be queued[0m
[[34m2020-10-02 14:07:09,239[0m] {[34mscheduler_job.py:[0m1025} INFO[0m - DAG [01mid_11[22m has 0/16 running and queued tasks[0m
[[34m2020-10-02 14:07:09,239[0m] {[34mscheduler_job.py:[0m1025} INFO[0m - DAG [01mid_31[22m has 0/16 running and queued tasks[0m
[[34m2020-10-02 14:07:09,245[0m] {[34mscheduler_job.py:[0m1085} INFO[0m - Setting the following tasks to queued state:
	[01m<TaskInstance: id_11.id_process_grib_hrrr 2020-10-02 20:06:00+00:00 [scheduled]>
	<TaskInstance: id_31.id_process_csv_gfs 2020-10-02 19:13:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 14:07:09,282[0m] {[34mscheduler_job.py:[0m1159} INFO[0m - Setting the following 2 tasks to queued state:
	[01m<TaskInstance: id_11.id_process_grib_hrrr 2020-10-02 20:06:00+00:00 [queued]>
	<TaskInstance: id_31.id_process_csv_gfs 2020-10-02 19:13:00+00:00 [queued]>[22m[0m
[[34m2020-10-02 14:07:09,282[0m] {[34mscheduler_job.py:[0m1195} INFO[0m - Sending [01m('id_11', 'id_process_grib_hrrr', datetime.datetime(2020, 10, 2, 20, 6, tzinfo=<Timezone [UTC]>), 1)[22m to executor with priority 3 and queue [01mdefault[22m[0m
[[34m2020-10-02 14:07:09,282[0m] {[34mbase_executor.py:[0m58} INFO[0m - Adding to queue: [01m['airflow', 'run', 'id_11', 'id_process_grib_hrrr', '2020-10-02T20:06:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[[34m2020-10-02 14:07:09,283[0m] {[34mscheduler_job.py:[0m1195} INFO[0m - Sending [01m('id_31', 'id_process_csv_gfs', datetime.datetime(2020, 10, 2, 19, 13, tzinfo=<Timezone [UTC]>), 1)[22m to executor with priority 2 and queue [01mdefault[22m[0m
[[34m2020-10-02 14:07:09,283[0m] {[34mbase_executor.py:[0m58} INFO[0m - Adding to queue: [01m['airflow', 'run', 'id_31', 'id_process_csv_gfs', '2020-10-02T19:13:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[[34m2020-10-02 14:07:09,283[0m] {[34msequential_executor.py:[0m54} INFO[0m - Executing command: [01m['airflow', 'run', 'id_11', 'id_process_grib_hrrr', '2020-10-02T20:06:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[2020-10-02 14:07:10,721] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-10-02 14:07:10,722] {dagbag.py:417} INFO - Filling up the DagBag from /home/csmith/pgrad/airflow/dags/pgrad_dag.py
Running %s on host %s <TaskInstance: id_11.id_process_grib_hrrr 2020-10-02T20:06:00+00:00 [queued]> penguin
[[34m2020-10-02 14:07:16,049[0m] {[34msequential_executor.py:[0m54} INFO[0m - Executing command: [01m['airflow', 'run', 'id_31', 'id_process_csv_gfs', '2020-10-02T19:13:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[2020-10-02 14:07:17,186] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-10-02 14:07:17,187] {dagbag.py:417} INFO - Filling up the DagBag from /home/csmith/pgrad/airflow/dags/pgrad_dag.py
Running %s on host %s <TaskInstance: id_31.id_process_csv_gfs 2020-10-02T19:13:00+00:00 [queued]> penguin
[[34m2020-10-02 14:07:22,500[0m] {[34mscheduler_job.py:[0m1334} INFO[0m - Executor reports execution of [01mid_11[22m.[01mid_process_grib_hrrr[22m execution_date=[01m2020-10-02 20:06:00+00:00[22m exited with status [01msuccess[22m for try_number 1[0m
[[34m2020-10-02 14:07:22,505[0m] {[34mscheduler_job.py:[0m1334} INFO[0m - Executor reports execution of [01mid_31[22m.[01mid_process_csv_gfs[22m execution_date=[01m2020-10-02 19:13:00+00:00[22m exited with status [01msuccess[22m for try_number 1[0m
[[34m2020-10-02 14:07:23,559[0m] {[34mscheduler_job.py:[0m963} INFO[0m - 2 tasks up for execution:
	[01m<TaskInstance: id_11.id_calc_pgrad_hrrr 2020-10-02 19:06:00+00:00 [scheduled]>
	<TaskInstance: id_21.id_calc_pgrad_nam 2020-10-02 19:09:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 14:07:23,564[0m] {[34mscheduler_job.py:[0m997} INFO[0m - Figuring out tasks to run in Pool(name=[01mdefault_pool[22m) with 128 open slots and 2 task instances ready to be queued[0m
[[34m2020-10-02 14:07:23,565[0m] {[34mscheduler_job.py:[0m1025} INFO[0m - DAG [01mid_11[22m has 0/16 running and queued tasks[0m
[[34m2020-10-02 14:07:23,565[0m] {[34mscheduler_job.py:[0m1025} INFO[0m - DAG [01mid_21[22m has 0/16 running and queued tasks[0m
[[34m2020-10-02 14:07:23,570[0m] {[34mscheduler_job.py:[0m1085} INFO[0m - Setting the following tasks to queued state:
	[01m<TaskInstance: id_11.id_calc_pgrad_hrrr 2020-10-02 19:06:00+00:00 [scheduled]>
	<TaskInstance: id_21.id_calc_pgrad_nam 2020-10-02 19:09:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 14:07:23,618[0m] {[34mscheduler_job.py:[0m1159} INFO[0m - Setting the following 2 tasks to queued state:
	[01m<TaskInstance: id_11.id_calc_pgrad_hrrr 2020-10-02 19:06:00+00:00 [queued]>
	<TaskInstance: id_21.id_calc_pgrad_nam 2020-10-02 19:09:00+00:00 [queued]>[22m[0m
[[34m2020-10-02 14:07:23,618[0m] {[34mscheduler_job.py:[0m1195} INFO[0m - Sending [01m('id_11', 'id_calc_pgrad_hrrr', datetime.datetime(2020, 10, 2, 19, 6, tzinfo=<Timezone [UTC]>), 1)[22m to executor with priority 1 and queue [01mdefault[22m[0m
[[34m2020-10-02 14:07:23,618[0m] {[34mbase_executor.py:[0m58} INFO[0m - Adding to queue: [01m['airflow', 'run', 'id_11', 'id_calc_pgrad_hrrr', '2020-10-02T19:06:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[[34m2020-10-02 14:07:23,618[0m] {[34mscheduler_job.py:[0m1195} INFO[0m - Sending [01m('id_21', 'id_calc_pgrad_nam', datetime.datetime(2020, 10, 2, 19, 9, tzinfo=<Timezone [UTC]>), 1)[22m to executor with priority 1 and queue [01mdefault[22m[0m
[[34m2020-10-02 14:07:23,618[0m] {[34mbase_executor.py:[0m58} INFO[0m - Adding to queue: [01m['airflow', 'run', 'id_21', 'id_calc_pgrad_nam', '2020-10-02T19:09:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[[34m2020-10-02 14:07:23,618[0m] {[34msequential_executor.py:[0m54} INFO[0m - Executing command: [01m['airflow', 'run', 'id_11', 'id_calc_pgrad_hrrr', '2020-10-02T19:06:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[2020-10-02 14:07:25,409] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-10-02 14:07:25,409] {dagbag.py:417} INFO - Filling up the DagBag from /home/csmith/pgrad/airflow/dags/pgrad_dag.py
Running %s on host %s <TaskInstance: id_11.id_calc_pgrad_hrrr 2020-10-02T19:06:00+00:00 [queued]> penguin
[[34m2020-10-02 14:07:30,701[0m] {[34msequential_executor.py:[0m54} INFO[0m - Executing command: [01m['airflow', 'run', 'id_21', 'id_calc_pgrad_nam', '2020-10-02T19:09:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[2020-10-02 14:07:31,775] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-10-02 14:07:31,776] {dagbag.py:417} INFO - Filling up the DagBag from /home/csmith/pgrad/airflow/dags/pgrad_dag.py
Running %s on host %s <TaskInstance: id_21.id_calc_pgrad_nam 2020-10-02T19:09:00+00:00 [queued]> penguin
[[34m2020-10-02 14:07:37,095[0m] {[34mscheduler_job.py:[0m1334} INFO[0m - Executor reports execution of [01mid_11[22m.[01mid_calc_pgrad_hrrr[22m execution_date=[01m2020-10-02 19:06:00+00:00[22m exited with status [01msuccess[22m for try_number 1[0m
[[34m2020-10-02 14:07:37,103[0m] {[34mscheduler_job.py:[0m1334} INFO[0m - Executor reports execution of [01mid_21[22m.[01mid_calc_pgrad_nam[22m execution_date=[01m2020-10-02 19:09:00+00:00[22m exited with status [01msuccess[22m for try_number 1[0m
[[34m2020-10-02 14:07:38,174[0m] {[34mscheduler_job.py:[0m963} INFO[0m - 2 tasks up for execution:
	[01m<TaskInstance: id_11.id_process_csv_hrrr 2020-10-02 20:06:00+00:00 [scheduled]>
	<TaskInstance: id_31.id_calc_pgrad_gfs 2020-10-02 19:13:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 14:07:38,179[0m] {[34mscheduler_job.py:[0m997} INFO[0m - Figuring out tasks to run in Pool(name=[01mdefault_pool[22m) with 128 open slots and 2 task instances ready to be queued[0m
[[34m2020-10-02 14:07:38,179[0m] {[34mscheduler_job.py:[0m1025} INFO[0m - DAG [01mid_11[22m has 0/16 running and queued tasks[0m
[[34m2020-10-02 14:07:38,180[0m] {[34mscheduler_job.py:[0m1025} INFO[0m - DAG [01mid_31[22m has 0/16 running and queued tasks[0m
[[34m2020-10-02 14:07:38,188[0m] {[34mscheduler_job.py:[0m1085} INFO[0m - Setting the following tasks to queued state:
	[01m<TaskInstance: id_11.id_process_csv_hrrr 2020-10-02 20:06:00+00:00 [scheduled]>
	<TaskInstance: id_31.id_calc_pgrad_gfs 2020-10-02 19:13:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 14:07:38,244[0m] {[34mscheduler_job.py:[0m1159} INFO[0m - Setting the following 2 tasks to queued state:
	[01m<TaskInstance: id_11.id_process_csv_hrrr 2020-10-02 20:06:00+00:00 [queued]>
	<TaskInstance: id_31.id_calc_pgrad_gfs 2020-10-02 19:13:00+00:00 [queued]>[22m[0m
[[34m2020-10-02 14:07:38,244[0m] {[34mscheduler_job.py:[0m1195} INFO[0m - Sending [01m('id_11', 'id_process_csv_hrrr', datetime.datetime(2020, 10, 2, 20, 6, tzinfo=<Timezone [UTC]>), 1)[22m to executor with priority 2 and queue [01mdefault[22m[0m
[[34m2020-10-02 14:07:38,244[0m] {[34mbase_executor.py:[0m58} INFO[0m - Adding to queue: [01m['airflow', 'run', 'id_11', 'id_process_csv_hrrr', '2020-10-02T20:06:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[[34m2020-10-02 14:07:38,245[0m] {[34mscheduler_job.py:[0m1195} INFO[0m - Sending [01m('id_31', 'id_calc_pgrad_gfs', datetime.datetime(2020, 10, 2, 19, 13, tzinfo=<Timezone [UTC]>), 1)[22m to executor with priority 1 and queue [01mdefault[22m[0m
[[34m2020-10-02 14:07:38,245[0m] {[34mbase_executor.py:[0m58} INFO[0m - Adding to queue: [01m['airflow', 'run', 'id_31', 'id_calc_pgrad_gfs', '2020-10-02T19:13:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[[34m2020-10-02 14:07:38,245[0m] {[34msequential_executor.py:[0m54} INFO[0m - Executing command: [01m['airflow', 'run', 'id_11', 'id_process_csv_hrrr', '2020-10-02T20:06:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[2020-10-02 14:07:39,831] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-10-02 14:07:39,832] {dagbag.py:417} INFO - Filling up the DagBag from /home/csmith/pgrad/airflow/dags/pgrad_dag.py
Running %s on host %s <TaskInstance: id_11.id_process_csv_hrrr 2020-10-02T20:06:00+00:00 [queued]> penguin
[[34m2020-10-02 14:07:45,125[0m] {[34msequential_executor.py:[0m54} INFO[0m - Executing command: [01m['airflow', 'run', 'id_31', 'id_calc_pgrad_gfs', '2020-10-02T19:13:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[2020-10-02 14:07:46,266] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-10-02 14:07:46,267] {dagbag.py:417} INFO - Filling up the DagBag from /home/csmith/pgrad/airflow/dags/pgrad_dag.py
Running %s on host %s <TaskInstance: id_31.id_calc_pgrad_gfs 2020-10-02T19:13:00+00:00 [queued]> penguin
[[34m2020-10-02 14:07:51,611[0m] {[34mscheduler_job.py:[0m1334} INFO[0m - Executor reports execution of [01mid_11[22m.[01mid_process_csv_hrrr[22m execution_date=[01m2020-10-02 20:06:00+00:00[22m exited with status [01msuccess[22m for try_number 1[0m
[[34m2020-10-02 14:07:51,615[0m] {[34mscheduler_job.py:[0m1334} INFO[0m - Executor reports execution of [01mid_31[22m.[01mid_calc_pgrad_gfs[22m execution_date=[01m2020-10-02 19:13:00+00:00[22m exited with status [01msuccess[22m for try_number 1[0m
[[34m2020-10-02 14:07:54,666[0m] {[34mscheduler_job.py:[0m963} INFO[0m - 1 tasks up for execution:
	[01m<TaskInstance: id_11.id_calc_pgrad_hrrr 2020-10-02 20:06:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 14:07:54,671[0m] {[34mscheduler_job.py:[0m997} INFO[0m - Figuring out tasks to run in Pool(name=[01mdefault_pool[22m) with 128 open slots and 1 task instances ready to be queued[0m
[[34m2020-10-02 14:07:54,671[0m] {[34mscheduler_job.py:[0m1025} INFO[0m - DAG [01mid_11[22m has 0/16 running and queued tasks[0m
[[34m2020-10-02 14:07:54,686[0m] {[34mscheduler_job.py:[0m1085} INFO[0m - Setting the following tasks to queued state:
	[01m<TaskInstance: id_11.id_calc_pgrad_hrrr 2020-10-02 20:06:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 14:07:54,733[0m] {[34mscheduler_job.py:[0m1159} INFO[0m - Setting the following 1 tasks to queued state:
	[01m<TaskInstance: id_11.id_calc_pgrad_hrrr 2020-10-02 20:06:00+00:00 [queued]>[22m[0m
[[34m2020-10-02 14:07:54,733[0m] {[34mscheduler_job.py:[0m1195} INFO[0m - Sending [01m('id_11', 'id_calc_pgrad_hrrr', datetime.datetime(2020, 10, 2, 20, 6, tzinfo=<Timezone [UTC]>), 1)[22m to executor with priority 1 and queue [01mdefault[22m[0m
[[34m2020-10-02 14:07:54,733[0m] {[34mbase_executor.py:[0m58} INFO[0m - Adding to queue: [01m['airflow', 'run', 'id_11', 'id_calc_pgrad_hrrr', '2020-10-02T20:06:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[[34m2020-10-02 14:07:54,733[0m] {[34msequential_executor.py:[0m54} INFO[0m - Executing command: [01m['airflow', 'run', 'id_11', 'id_calc_pgrad_hrrr', '2020-10-02T20:06:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[2020-10-02 14:07:56,172] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-10-02 14:07:56,173] {dagbag.py:417} INFO - Filling up the DagBag from /home/csmith/pgrad/airflow/dags/pgrad_dag.py
Running %s on host %s <TaskInstance: id_11.id_calc_pgrad_hrrr 2020-10-02T20:06:00+00:00 [queued]> penguin
[[34m2020-10-02 14:08:01,501[0m] {[34mscheduler_job.py:[0m1334} INFO[0m - Executor reports execution of [01mid_11[22m.[01mid_calc_pgrad_hrrr[22m execution_date=[01m2020-10-02 20:06:00+00:00[22m exited with status [01msuccess[22m for try_number 1[0m
[[34m2020-10-02 14:09:02,626[0m] {[34mscheduler_job.py:[0m963} INFO[0m - 1 tasks up for execution:
	[01m<TaskInstance: id_21.id_download_nam 2020-10-02 20:09:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 14:09:02,630[0m] {[34mscheduler_job.py:[0m997} INFO[0m - Figuring out tasks to run in Pool(name=[01mdefault_pool[22m) with 128 open slots and 1 task instances ready to be queued[0m
[[34m2020-10-02 14:09:02,631[0m] {[34mscheduler_job.py:[0m1025} INFO[0m - DAG [01mid_21[22m has 0/16 running and queued tasks[0m
[[34m2020-10-02 14:09:02,635[0m] {[34mscheduler_job.py:[0m1085} INFO[0m - Setting the following tasks to queued state:
	[01m<TaskInstance: id_21.id_download_nam 2020-10-02 20:09:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 14:09:02,667[0m] {[34mscheduler_job.py:[0m1159} INFO[0m - Setting the following 1 tasks to queued state:
	[01m<TaskInstance: id_21.id_download_nam 2020-10-02 20:09:00+00:00 [queued]>[22m[0m
[[34m2020-10-02 14:09:02,667[0m] {[34mscheduler_job.py:[0m1195} INFO[0m - Sending [01m('id_21', 'id_download_nam', datetime.datetime(2020, 10, 2, 20, 9, tzinfo=<Timezone [UTC]>), 1)[22m to executor with priority 4 and queue [01mdefault[22m[0m
[[34m2020-10-02 14:09:02,667[0m] {[34mbase_executor.py:[0m58} INFO[0m - Adding to queue: [01m['airflow', 'run', 'id_21', 'id_download_nam', '2020-10-02T20:09:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[[34m2020-10-02 14:09:02,667[0m] {[34msequential_executor.py:[0m54} INFO[0m - Executing command: [01m['airflow', 'run', 'id_21', 'id_download_nam', '2020-10-02T20:09:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[2020-10-02 14:09:03,794] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-10-02 14:09:03,794] {dagbag.py:417} INFO - Filling up the DagBag from /home/csmith/pgrad/airflow/dags/pgrad_dag.py
Running %s on host %s <TaskInstance: id_21.id_download_nam 2020-10-02T20:09:00+00:00 [queued]> penguin
[[34m2020-10-02 14:09:09,072[0m] {[34mscheduler_job.py:[0m1334} INFO[0m - Executor reports execution of [01mid_21[22m.[01mid_download_nam[22m execution_date=[01m2020-10-02 20:09:00+00:00[22m exited with status [01msuccess[22m for try_number 1[0m
[[34m2020-10-02 14:09:12,133[0m] {[34mscheduler_job.py:[0m963} INFO[0m - 1 tasks up for execution:
	[01m<TaskInstance: id_21.id_process_grib_nam 2020-10-02 20:09:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 14:09:12,135[0m] {[34mscheduler_job.py:[0m997} INFO[0m - Figuring out tasks to run in Pool(name=[01mdefault_pool[22m) with 128 open slots and 1 task instances ready to be queued[0m
[[34m2020-10-02 14:09:12,135[0m] {[34mscheduler_job.py:[0m1025} INFO[0m - DAG [01mid_21[22m has 0/16 running and queued tasks[0m
[[34m2020-10-02 14:09:12,140[0m] {[34mscheduler_job.py:[0m1085} INFO[0m - Setting the following tasks to queued state:
	[01m<TaskInstance: id_21.id_process_grib_nam 2020-10-02 20:09:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 14:09:12,178[0m] {[34mscheduler_job.py:[0m1159} INFO[0m - Setting the following 1 tasks to queued state:
	[01m<TaskInstance: id_21.id_process_grib_nam 2020-10-02 20:09:00+00:00 [queued]>[22m[0m
[[34m2020-10-02 14:09:12,178[0m] {[34mscheduler_job.py:[0m1195} INFO[0m - Sending [01m('id_21', 'id_process_grib_nam', datetime.datetime(2020, 10, 2, 20, 9, tzinfo=<Timezone [UTC]>), 1)[22m to executor with priority 3 and queue [01mdefault[22m[0m
[[34m2020-10-02 14:09:12,178[0m] {[34mbase_executor.py:[0m58} INFO[0m - Adding to queue: [01m['airflow', 'run', 'id_21', 'id_process_grib_nam', '2020-10-02T20:09:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[[34m2020-10-02 14:09:12,178[0m] {[34msequential_executor.py:[0m54} INFO[0m - Executing command: [01m['airflow', 'run', 'id_21', 'id_process_grib_nam', '2020-10-02T20:09:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[2020-10-02 14:09:13,391] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-10-02 14:09:13,391] {dagbag.py:417} INFO - Filling up the DagBag from /home/csmith/pgrad/airflow/dags/pgrad_dag.py
Running %s on host %s <TaskInstance: id_21.id_process_grib_nam 2020-10-02T20:09:00+00:00 [queued]> penguin
[[34m2020-10-02 14:09:18,710[0m] {[34mscheduler_job.py:[0m1334} INFO[0m - Executor reports execution of [01mid_21[22m.[01mid_process_grib_nam[22m execution_date=[01m2020-10-02 20:09:00+00:00[22m exited with status [01msuccess[22m for try_number 1[0m
[[34m2020-10-02 14:09:21,780[0m] {[34mscheduler_job.py:[0m963} INFO[0m - 1 tasks up for execution:
	[01m<TaskInstance: id_21.id_process_csv_nam 2020-10-02 20:09:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 14:09:21,786[0m] {[34mscheduler_job.py:[0m997} INFO[0m - Figuring out tasks to run in Pool(name=[01mdefault_pool[22m) with 128 open slots and 1 task instances ready to be queued[0m
[[34m2020-10-02 14:09:21,786[0m] {[34mscheduler_job.py:[0m1025} INFO[0m - DAG [01mid_21[22m has 0/16 running and queued tasks[0m
[[34m2020-10-02 14:09:21,791[0m] {[34mscheduler_job.py:[0m1085} INFO[0m - Setting the following tasks to queued state:
	[01m<TaskInstance: id_21.id_process_csv_nam 2020-10-02 20:09:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 14:09:21,834[0m] {[34mscheduler_job.py:[0m1159} INFO[0m - Setting the following 1 tasks to queued state:
	[01m<TaskInstance: id_21.id_process_csv_nam 2020-10-02 20:09:00+00:00 [queued]>[22m[0m
[[34m2020-10-02 14:09:21,834[0m] {[34mscheduler_job.py:[0m1195} INFO[0m - Sending [01m('id_21', 'id_process_csv_nam', datetime.datetime(2020, 10, 2, 20, 9, tzinfo=<Timezone [UTC]>), 1)[22m to executor with priority 2 and queue [01mdefault[22m[0m
[[34m2020-10-02 14:09:21,834[0m] {[34mbase_executor.py:[0m58} INFO[0m - Adding to queue: [01m['airflow', 'run', 'id_21', 'id_process_csv_nam', '2020-10-02T20:09:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[[34m2020-10-02 14:09:21,835[0m] {[34msequential_executor.py:[0m54} INFO[0m - Executing command: [01m['airflow', 'run', 'id_21', 'id_process_csv_nam', '2020-10-02T20:09:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[2020-10-02 14:09:23,102] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-10-02 14:09:23,102] {dagbag.py:417} INFO - Filling up the DagBag from /home/csmith/pgrad/airflow/dags/pgrad_dag.py
Running %s on host %s <TaskInstance: id_21.id_process_csv_nam 2020-10-02T20:09:00+00:00 [queued]> penguin
[[34m2020-10-02 14:09:28,382[0m] {[34mscheduler_job.py:[0m1334} INFO[0m - Executor reports execution of [01mid_21[22m.[01mid_process_csv_nam[22m execution_date=[01m2020-10-02 20:09:00+00:00[22m exited with status [01msuccess[22m for try_number 1[0m
[[34m2020-10-02 14:09:31,457[0m] {[34mscheduler_job.py:[0m963} INFO[0m - 1 tasks up for execution:
	[01m<TaskInstance: id_21.id_calc_pgrad_nam 2020-10-02 20:09:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 14:09:31,463[0m] {[34mscheduler_job.py:[0m997} INFO[0m - Figuring out tasks to run in Pool(name=[01mdefault_pool[22m) with 128 open slots and 1 task instances ready to be queued[0m
[[34m2020-10-02 14:09:31,463[0m] {[34mscheduler_job.py:[0m1025} INFO[0m - DAG [01mid_21[22m has 0/16 running and queued tasks[0m
[[34m2020-10-02 14:09:31,468[0m] {[34mscheduler_job.py:[0m1085} INFO[0m - Setting the following tasks to queued state:
	[01m<TaskInstance: id_21.id_calc_pgrad_nam 2020-10-02 20:09:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 14:09:31,490[0m] {[34mscheduler_job.py:[0m1159} INFO[0m - Setting the following 1 tasks to queued state:
	[01m<TaskInstance: id_21.id_calc_pgrad_nam 2020-10-02 20:09:00+00:00 [queued]>[22m[0m
[[34m2020-10-02 14:09:31,491[0m] {[34mscheduler_job.py:[0m1195} INFO[0m - Sending [01m('id_21', 'id_calc_pgrad_nam', datetime.datetime(2020, 10, 2, 20, 9, tzinfo=<Timezone [UTC]>), 1)[22m to executor with priority 1 and queue [01mdefault[22m[0m
[[34m2020-10-02 14:09:31,491[0m] {[34mbase_executor.py:[0m58} INFO[0m - Adding to queue: [01m['airflow', 'run', 'id_21', 'id_calc_pgrad_nam', '2020-10-02T20:09:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[[34m2020-10-02 14:09:31,491[0m] {[34msequential_executor.py:[0m54} INFO[0m - Executing command: [01m['airflow', 'run', 'id_21', 'id_calc_pgrad_nam', '2020-10-02T20:09:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[2020-10-02 14:09:32,672] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-10-02 14:09:32,673] {dagbag.py:417} INFO - Filling up the DagBag from /home/csmith/pgrad/airflow/dags/pgrad_dag.py
Running %s on host %s <TaskInstance: id_21.id_calc_pgrad_nam 2020-10-02T20:09:00+00:00 [queued]> penguin
[[34m2020-10-02 14:09:37,956[0m] {[34mscheduler_job.py:[0m1334} INFO[0m - Executor reports execution of [01mid_21[22m.[01mid_calc_pgrad_nam[22m execution_date=[01m2020-10-02 20:09:00+00:00[22m exited with status [01msuccess[22m for try_number 1[0m
[[34m2020-10-02 14:13:03,239[0m] {[34mscheduler_job.py:[0m963} INFO[0m - 1 tasks up for execution:
	[01m<TaskInstance: id_31.id_download_gfs 2020-10-02 20:13:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 14:13:03,242[0m] {[34mscheduler_job.py:[0m997} INFO[0m - Figuring out tasks to run in Pool(name=[01mdefault_pool[22m) with 128 open slots and 1 task instances ready to be queued[0m
[[34m2020-10-02 14:13:03,242[0m] {[34mscheduler_job.py:[0m1025} INFO[0m - DAG [01mid_31[22m has 0/16 running and queued tasks[0m
[[34m2020-10-02 14:13:03,245[0m] {[34mscheduler_job.py:[0m1085} INFO[0m - Setting the following tasks to queued state:
	[01m<TaskInstance: id_31.id_download_gfs 2020-10-02 20:13:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 14:13:03,284[0m] {[34mscheduler_job.py:[0m1159} INFO[0m - Setting the following 1 tasks to queued state:
	[01m<TaskInstance: id_31.id_download_gfs 2020-10-02 20:13:00+00:00 [queued]>[22m[0m
[[34m2020-10-02 14:13:03,284[0m] {[34mscheduler_job.py:[0m1195} INFO[0m - Sending [01m('id_31', 'id_download_gfs', datetime.datetime(2020, 10, 2, 20, 13, tzinfo=<Timezone [UTC]>), 1)[22m to executor with priority 4 and queue [01mdefault[22m[0m
[[34m2020-10-02 14:13:03,284[0m] {[34mbase_executor.py:[0m58} INFO[0m - Adding to queue: [01m['airflow', 'run', 'id_31', 'id_download_gfs', '2020-10-02T20:13:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[[34m2020-10-02 14:13:03,285[0m] {[34msequential_executor.py:[0m54} INFO[0m - Executing command: [01m['airflow', 'run', 'id_31', 'id_download_gfs', '2020-10-02T20:13:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[2020-10-02 14:13:04,497] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-10-02 14:13:04,498] {dagbag.py:417} INFO - Filling up the DagBag from /home/csmith/pgrad/airflow/dags/pgrad_dag.py
Running %s on host %s <TaskInstance: id_31.id_download_gfs 2020-10-02T20:13:00+00:00 [queued]> penguin
[[34m2020-10-02 14:13:09,791[0m] {[34mscheduler_job.py:[0m1334} INFO[0m - Executor reports execution of [01mid_31[22m.[01mid_download_gfs[22m execution_date=[01m2020-10-02 20:13:00+00:00[22m exited with status [01msuccess[22m for try_number 1[0m
[[34m2020-10-02 14:13:12,848[0m] {[34mscheduler_job.py:[0m963} INFO[0m - 1 tasks up for execution:
	[01m<TaskInstance: id_31.id_process_grib_gfs 2020-10-02 20:13:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 14:13:12,852[0m] {[34mscheduler_job.py:[0m997} INFO[0m - Figuring out tasks to run in Pool(name=[01mdefault_pool[22m) with 128 open slots and 1 task instances ready to be queued[0m
[[34m2020-10-02 14:13:12,852[0m] {[34mscheduler_job.py:[0m1025} INFO[0m - DAG [01mid_31[22m has 0/16 running and queued tasks[0m
[[34m2020-10-02 14:13:12,855[0m] {[34mscheduler_job.py:[0m1085} INFO[0m - Setting the following tasks to queued state:
	[01m<TaskInstance: id_31.id_process_grib_gfs 2020-10-02 20:13:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 14:13:12,891[0m] {[34mscheduler_job.py:[0m1159} INFO[0m - Setting the following 1 tasks to queued state:
	[01m<TaskInstance: id_31.id_process_grib_gfs 2020-10-02 20:13:00+00:00 [queued]>[22m[0m
[[34m2020-10-02 14:13:12,892[0m] {[34mscheduler_job.py:[0m1195} INFO[0m - Sending [01m('id_31', 'id_process_grib_gfs', datetime.datetime(2020, 10, 2, 20, 13, tzinfo=<Timezone [UTC]>), 1)[22m to executor with priority 3 and queue [01mdefault[22m[0m
[[34m2020-10-02 14:13:12,892[0m] {[34mbase_executor.py:[0m58} INFO[0m - Adding to queue: [01m['airflow', 'run', 'id_31', 'id_process_grib_gfs', '2020-10-02T20:13:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[[34m2020-10-02 14:13:12,892[0m] {[34msequential_executor.py:[0m54} INFO[0m - Executing command: [01m['airflow', 'run', 'id_31', 'id_process_grib_gfs', '2020-10-02T20:13:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[2020-10-02 14:13:14,088] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-10-02 14:13:14,088] {dagbag.py:417} INFO - Filling up the DagBag from /home/csmith/pgrad/airflow/dags/pgrad_dag.py
Running %s on host %s <TaskInstance: id_31.id_process_grib_gfs 2020-10-02T20:13:00+00:00 [queued]> penguin
[[34m2020-10-02 14:13:19,350[0m] {[34mscheduler_job.py:[0m1334} INFO[0m - Executor reports execution of [01mid_31[22m.[01mid_process_grib_gfs[22m execution_date=[01m2020-10-02 20:13:00+00:00[22m exited with status [01msuccess[22m for try_number 1[0m
[[34m2020-10-02 14:13:22,417[0m] {[34mscheduler_job.py:[0m963} INFO[0m - 1 tasks up for execution:
	[01m<TaskInstance: id_31.id_process_csv_gfs 2020-10-02 20:13:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 14:13:22,420[0m] {[34mscheduler_job.py:[0m997} INFO[0m - Figuring out tasks to run in Pool(name=[01mdefault_pool[22m) with 128 open slots and 1 task instances ready to be queued[0m
[[34m2020-10-02 14:13:22,420[0m] {[34mscheduler_job.py:[0m1025} INFO[0m - DAG [01mid_31[22m has 0/16 running and queued tasks[0m
[[34m2020-10-02 14:13:22,424[0m] {[34mscheduler_job.py:[0m1085} INFO[0m - Setting the following tasks to queued state:
	[01m<TaskInstance: id_31.id_process_csv_gfs 2020-10-02 20:13:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 14:13:22,456[0m] {[34mscheduler_job.py:[0m1159} INFO[0m - Setting the following 1 tasks to queued state:
	[01m<TaskInstance: id_31.id_process_csv_gfs 2020-10-02 20:13:00+00:00 [queued]>[22m[0m
[[34m2020-10-02 14:13:22,456[0m] {[34mscheduler_job.py:[0m1195} INFO[0m - Sending [01m('id_31', 'id_process_csv_gfs', datetime.datetime(2020, 10, 2, 20, 13, tzinfo=<Timezone [UTC]>), 1)[22m to executor with priority 2 and queue [01mdefault[22m[0m
[[34m2020-10-02 14:13:22,456[0m] {[34mbase_executor.py:[0m58} INFO[0m - Adding to queue: [01m['airflow', 'run', 'id_31', 'id_process_csv_gfs', '2020-10-02T20:13:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[[34m2020-10-02 14:13:22,456[0m] {[34msequential_executor.py:[0m54} INFO[0m - Executing command: [01m['airflow', 'run', 'id_31', 'id_process_csv_gfs', '2020-10-02T20:13:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[2020-10-02 14:13:23,708] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-10-02 14:13:23,708] {dagbag.py:417} INFO - Filling up the DagBag from /home/csmith/pgrad/airflow/dags/pgrad_dag.py
Running %s on host %s <TaskInstance: id_31.id_process_csv_gfs 2020-10-02T20:13:00+00:00 [queued]> penguin
[[34m2020-10-02 14:13:29,030[0m] {[34mscheduler_job.py:[0m1334} INFO[0m - Executor reports execution of [01mid_31[22m.[01mid_process_csv_gfs[22m execution_date=[01m2020-10-02 20:13:00+00:00[22m exited with status [01msuccess[22m for try_number 1[0m
[[34m2020-10-02 14:13:32,101[0m] {[34mscheduler_job.py:[0m963} INFO[0m - 1 tasks up for execution:
	[01m<TaskInstance: id_31.id_calc_pgrad_gfs 2020-10-02 20:13:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 14:13:32,107[0m] {[34mscheduler_job.py:[0m997} INFO[0m - Figuring out tasks to run in Pool(name=[01mdefault_pool[22m) with 128 open slots and 1 task instances ready to be queued[0m
[[34m2020-10-02 14:13:32,107[0m] {[34mscheduler_job.py:[0m1025} INFO[0m - DAG [01mid_31[22m has 0/16 running and queued tasks[0m
[[34m2020-10-02 14:13:32,114[0m] {[34mscheduler_job.py:[0m1085} INFO[0m - Setting the following tasks to queued state:
	[01m<TaskInstance: id_31.id_calc_pgrad_gfs 2020-10-02 20:13:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 14:13:32,169[0m] {[34mscheduler_job.py:[0m1159} INFO[0m - Setting the following 1 tasks to queued state:
	[01m<TaskInstance: id_31.id_calc_pgrad_gfs 2020-10-02 20:13:00+00:00 [queued]>[22m[0m
[[34m2020-10-02 14:13:32,170[0m] {[34mscheduler_job.py:[0m1195} INFO[0m - Sending [01m('id_31', 'id_calc_pgrad_gfs', datetime.datetime(2020, 10, 2, 20, 13, tzinfo=<Timezone [UTC]>), 1)[22m to executor with priority 1 and queue [01mdefault[22m[0m
[[34m2020-10-02 14:13:32,170[0m] {[34mbase_executor.py:[0m58} INFO[0m - Adding to queue: [01m['airflow', 'run', 'id_31', 'id_calc_pgrad_gfs', '2020-10-02T20:13:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[[34m2020-10-02 14:13:32,170[0m] {[34msequential_executor.py:[0m54} INFO[0m - Executing command: [01m['airflow', 'run', 'id_31', 'id_calc_pgrad_gfs', '2020-10-02T20:13:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[2020-10-02 14:13:33,278] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-10-02 14:13:33,278] {dagbag.py:417} INFO - Filling up the DagBag from /home/csmith/pgrad/airflow/dags/pgrad_dag.py
Running %s on host %s <TaskInstance: id_31.id_calc_pgrad_gfs 2020-10-02T20:13:00+00:00 [queued]> penguin
[[34m2020-10-02 14:13:38,528[0m] {[34mscheduler_job.py:[0m1334} INFO[0m - Executor reports execution of [01mid_31[22m.[01mid_calc_pgrad_gfs[22m execution_date=[01m2020-10-02 20:13:00+00:00[22m exited with status [01msuccess[22m for try_number 1[0m
[[34m2020-10-02 14:17:01,809[0m] {[34mscheduler_job.py:[0m963} INFO[0m - 1 tasks up for execution:
	[01m<TaskInstance: id_56.id_plot_data 2020-10-02 20:17:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 14:17:01,813[0m] {[34mscheduler_job.py:[0m997} INFO[0m - Figuring out tasks to run in Pool(name=[01mdefault_pool[22m) with 128 open slots and 1 task instances ready to be queued[0m
[[34m2020-10-02 14:17:01,813[0m] {[34mscheduler_job.py:[0m1025} INFO[0m - DAG [01mid_56[22m has 0/16 running and queued tasks[0m
[[34m2020-10-02 14:17:01,816[0m] {[34mscheduler_job.py:[0m1085} INFO[0m - Setting the following tasks to queued state:
	[01m<TaskInstance: id_56.id_plot_data 2020-10-02 20:17:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 14:17:01,849[0m] {[34mscheduler_job.py:[0m1159} INFO[0m - Setting the following 1 tasks to queued state:
	[01m<TaskInstance: id_56.id_plot_data 2020-10-02 20:17:00+00:00 [queued]>[22m[0m
[[34m2020-10-02 14:17:01,850[0m] {[34mscheduler_job.py:[0m1195} INFO[0m - Sending [01m('id_56', 'id_plot_data', datetime.datetime(2020, 10, 2, 20, 17, tzinfo=<Timezone [UTC]>), 1)[22m to executor with priority 1 and queue [01mdefault[22m[0m
[[34m2020-10-02 14:17:01,850[0m] {[34mbase_executor.py:[0m58} INFO[0m - Adding to queue: [01m['airflow', 'run', 'id_56', 'id_plot_data', '2020-10-02T20:17:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[[34m2020-10-02 14:17:01,850[0m] {[34msequential_executor.py:[0m54} INFO[0m - Executing command: [01m['airflow', 'run', 'id_56', 'id_plot_data', '2020-10-02T20:17:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[2020-10-02 14:17:03,074] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-10-02 14:17:03,074] {dagbag.py:417} INFO - Filling up the DagBag from /home/csmith/pgrad/airflow/dags/pgrad_dag.py
Running %s on host %s <TaskInstance: id_56.id_plot_data 2020-10-02T20:17:00+00:00 [queued]> penguin
[[34m2020-10-02 14:17:33,437[0m] {[34mscheduler_job.py:[0m1334} INFO[0m - Executor reports execution of [01mid_56[22m.[01mid_plot_data[22m execution_date=[01m2020-10-02 20:17:00+00:00[22m exited with status [01msuccess[22m for try_number 1[0m
[[34m2020-10-02 15:05:01,832[0m] {[34mscheduler_job.py:[0m963} INFO[0m - 1 tasks up for execution:
	[01m<TaskInstance: id_01.id_cleanup 2020-10-02 21:05:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 15:05:01,837[0m] {[34mscheduler_job.py:[0m997} INFO[0m - Figuring out tasks to run in Pool(name=[01mdefault_pool[22m) with 128 open slots and 1 task instances ready to be queued[0m
[[34m2020-10-02 15:05:01,837[0m] {[34mscheduler_job.py:[0m1025} INFO[0m - DAG [01mid_01[22m has 0/16 running and queued tasks[0m
[[34m2020-10-02 15:05:01,840[0m] {[34mscheduler_job.py:[0m1085} INFO[0m - Setting the following tasks to queued state:
	[01m<TaskInstance: id_01.id_cleanup 2020-10-02 21:05:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 15:05:01,879[0m] {[34mscheduler_job.py:[0m1159} INFO[0m - Setting the following 1 tasks to queued state:
	[01m<TaskInstance: id_01.id_cleanup 2020-10-02 21:05:00+00:00 [queued]>[22m[0m
[[34m2020-10-02 15:05:01,880[0m] {[34mscheduler_job.py:[0m1195} INFO[0m - Sending [01m('id_01', 'id_cleanup', datetime.datetime(2020, 10, 2, 21, 5, tzinfo=<Timezone [UTC]>), 1)[22m to executor with priority 1 and queue [01mdefault[22m[0m
[[34m2020-10-02 15:05:01,880[0m] {[34mbase_executor.py:[0m58} INFO[0m - Adding to queue: [01m['airflow', 'run', 'id_01', 'id_cleanup', '2020-10-02T21:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[[34m2020-10-02 15:05:01,880[0m] {[34msequential_executor.py:[0m54} INFO[0m - Executing command: [01m['airflow', 'run', 'id_01', 'id_cleanup', '2020-10-02T21:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[2020-10-02 15:05:03,854] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-10-02 15:05:03,855] {dagbag.py:417} INFO - Filling up the DagBag from /home/csmith/pgrad/airflow/dags/pgrad_dag.py
Running %s on host %s <TaskInstance: id_01.id_cleanup 2020-10-02T21:05:00+00:00 [queued]> penguin
[[34m2020-10-02 15:05:09,144[0m] {[34mscheduler_job.py:[0m1334} INFO[0m - Executor reports execution of [01mid_01[22m.[01mid_cleanup[22m execution_date=[01m2020-10-02 21:05:00+00:00[22m exited with status [01msuccess[22m for try_number 1[0m
[[34m2020-10-02 15:06:02,269[0m] {[34mscheduler_job.py:[0m963} INFO[0m - 1 tasks up for execution:
	[01m<TaskInstance: id_11.id_download_hrrr 2020-10-02 21:06:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 15:06:02,274[0m] {[34mscheduler_job.py:[0m997} INFO[0m - Figuring out tasks to run in Pool(name=[01mdefault_pool[22m) with 128 open slots and 1 task instances ready to be queued[0m
[[34m2020-10-02 15:06:02,274[0m] {[34mscheduler_job.py:[0m1025} INFO[0m - DAG [01mid_11[22m has 0/16 running and queued tasks[0m
[[34m2020-10-02 15:06:02,279[0m] {[34mscheduler_job.py:[0m1085} INFO[0m - Setting the following tasks to queued state:
	[01m<TaskInstance: id_11.id_download_hrrr 2020-10-02 21:06:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 15:06:02,326[0m] {[34mscheduler_job.py:[0m1159} INFO[0m - Setting the following 1 tasks to queued state:
	[01m<TaskInstance: id_11.id_download_hrrr 2020-10-02 21:06:00+00:00 [queued]>[22m[0m
[[34m2020-10-02 15:06:02,327[0m] {[34mscheduler_job.py:[0m1195} INFO[0m - Sending [01m('id_11', 'id_download_hrrr', datetime.datetime(2020, 10, 2, 21, 6, tzinfo=<Timezone [UTC]>), 1)[22m to executor with priority 4 and queue [01mdefault[22m[0m
[[34m2020-10-02 15:06:02,327[0m] {[34mbase_executor.py:[0m58} INFO[0m - Adding to queue: [01m['airflow', 'run', 'id_11', 'id_download_hrrr', '2020-10-02T21:06:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[[34m2020-10-02 15:06:02,327[0m] {[34msequential_executor.py:[0m54} INFO[0m - Executing command: [01m['airflow', 'run', 'id_11', 'id_download_hrrr', '2020-10-02T21:06:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[2020-10-02 15:06:03,841] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-10-02 15:06:03,841] {dagbag.py:417} INFO - Filling up the DagBag from /home/csmith/pgrad/airflow/dags/pgrad_dag.py
Running %s on host %s <TaskInstance: id_11.id_download_hrrr 2020-10-02T21:06:00+00:00 [queued]> penguin
[[34m2020-10-02 15:06:09,185[0m] {[34mscheduler_job.py:[0m1334} INFO[0m - Executor reports execution of [01mid_11[22m.[01mid_download_hrrr[22m execution_date=[01m2020-10-02 21:06:00+00:00[22m exited with status [01msuccess[22m for try_number 1[0m
[[34m2020-10-02 15:06:12,236[0m] {[34mscheduler_job.py:[0m963} INFO[0m - 1 tasks up for execution:
	[01m<TaskInstance: id_11.id_process_grib_hrrr 2020-10-02 21:06:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 15:06:12,239[0m] {[34mscheduler_job.py:[0m997} INFO[0m - Figuring out tasks to run in Pool(name=[01mdefault_pool[22m) with 128 open slots and 1 task instances ready to be queued[0m
[[34m2020-10-02 15:06:12,239[0m] {[34mscheduler_job.py:[0m1025} INFO[0m - DAG [01mid_11[22m has 0/16 running and queued tasks[0m
[[34m2020-10-02 15:06:12,244[0m] {[34mscheduler_job.py:[0m1085} INFO[0m - Setting the following tasks to queued state:
	[01m<TaskInstance: id_11.id_process_grib_hrrr 2020-10-02 21:06:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 15:06:12,280[0m] {[34mscheduler_job.py:[0m1159} INFO[0m - Setting the following 1 tasks to queued state:
	[01m<TaskInstance: id_11.id_process_grib_hrrr 2020-10-02 21:06:00+00:00 [queued]>[22m[0m
[[34m2020-10-02 15:06:12,280[0m] {[34mscheduler_job.py:[0m1195} INFO[0m - Sending [01m('id_11', 'id_process_grib_hrrr', datetime.datetime(2020, 10, 2, 21, 6, tzinfo=<Timezone [UTC]>), 1)[22m to executor with priority 3 and queue [01mdefault[22m[0m
[[34m2020-10-02 15:06:12,280[0m] {[34mbase_executor.py:[0m58} INFO[0m - Adding to queue: [01m['airflow', 'run', 'id_11', 'id_process_grib_hrrr', '2020-10-02T21:06:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[[34m2020-10-02 15:06:12,280[0m] {[34msequential_executor.py:[0m54} INFO[0m - Executing command: [01m['airflow', 'run', 'id_11', 'id_process_grib_hrrr', '2020-10-02T21:06:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[2020-10-02 15:06:13,517] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-10-02 15:06:13,517] {dagbag.py:417} INFO - Filling up the DagBag from /home/csmith/pgrad/airflow/dags/pgrad_dag.py
Running %s on host %s <TaskInstance: id_11.id_process_grib_hrrr 2020-10-02T21:06:00+00:00 [queued]> penguin
[[34m2020-10-02 15:06:18,802[0m] {[34mscheduler_job.py:[0m1334} INFO[0m - Executor reports execution of [01mid_11[22m.[01mid_process_grib_hrrr[22m execution_date=[01m2020-10-02 21:06:00+00:00[22m exited with status [01msuccess[22m for try_number 1[0m
[[34m2020-10-02 15:06:21,868[0m] {[34mscheduler_job.py:[0m963} INFO[0m - 1 tasks up for execution:
	[01m<TaskInstance: id_11.id_process_csv_hrrr 2020-10-02 21:06:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 15:06:21,871[0m] {[34mscheduler_job.py:[0m997} INFO[0m - Figuring out tasks to run in Pool(name=[01mdefault_pool[22m) with 128 open slots and 1 task instances ready to be queued[0m
[[34m2020-10-02 15:06:21,871[0m] {[34mscheduler_job.py:[0m1025} INFO[0m - DAG [01mid_11[22m has 0/16 running and queued tasks[0m
[[34m2020-10-02 15:06:21,874[0m] {[34mscheduler_job.py:[0m1085} INFO[0m - Setting the following tasks to queued state:
	[01m<TaskInstance: id_11.id_process_csv_hrrr 2020-10-02 21:06:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 15:06:21,911[0m] {[34mscheduler_job.py:[0m1159} INFO[0m - Setting the following 1 tasks to queued state:
	[01m<TaskInstance: id_11.id_process_csv_hrrr 2020-10-02 21:06:00+00:00 [queued]>[22m[0m
[[34m2020-10-02 15:06:21,911[0m] {[34mscheduler_job.py:[0m1195} INFO[0m - Sending [01m('id_11', 'id_process_csv_hrrr', datetime.datetime(2020, 10, 2, 21, 6, tzinfo=<Timezone [UTC]>), 1)[22m to executor with priority 2 and queue [01mdefault[22m[0m
[[34m2020-10-02 15:06:21,911[0m] {[34mbase_executor.py:[0m58} INFO[0m - Adding to queue: [01m['airflow', 'run', 'id_11', 'id_process_csv_hrrr', '2020-10-02T21:06:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[[34m2020-10-02 15:06:21,912[0m] {[34msequential_executor.py:[0m54} INFO[0m - Executing command: [01m['airflow', 'run', 'id_11', 'id_process_csv_hrrr', '2020-10-02T21:06:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[2020-10-02 15:06:23,208] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-10-02 15:06:23,208] {dagbag.py:417} INFO - Filling up the DagBag from /home/csmith/pgrad/airflow/dags/pgrad_dag.py
Running %s on host %s <TaskInstance: id_11.id_process_csv_hrrr 2020-10-02T21:06:00+00:00 [queued]> penguin
[[34m2020-10-02 15:06:28,477[0m] {[34mscheduler_job.py:[0m1334} INFO[0m - Executor reports execution of [01mid_11[22m.[01mid_process_csv_hrrr[22m execution_date=[01m2020-10-02 21:06:00+00:00[22m exited with status [01msuccess[22m for try_number 1[0m
[[34m2020-10-02 15:06:31,538[0m] {[34mscheduler_job.py:[0m963} INFO[0m - 1 tasks up for execution:
	[01m<TaskInstance: id_11.id_calc_pgrad_hrrr 2020-10-02 21:06:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 15:06:31,544[0m] {[34mscheduler_job.py:[0m997} INFO[0m - Figuring out tasks to run in Pool(name=[01mdefault_pool[22m) with 128 open slots and 1 task instances ready to be queued[0m
[[34m2020-10-02 15:06:31,544[0m] {[34mscheduler_job.py:[0m1025} INFO[0m - DAG [01mid_11[22m has 0/16 running and queued tasks[0m
[[34m2020-10-02 15:06:31,550[0m] {[34mscheduler_job.py:[0m1085} INFO[0m - Setting the following tasks to queued state:
	[01m<TaskInstance: id_11.id_calc_pgrad_hrrr 2020-10-02 21:06:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 15:06:31,619[0m] {[34mscheduler_job.py:[0m1159} INFO[0m - Setting the following 1 tasks to queued state:
	[01m<TaskInstance: id_11.id_calc_pgrad_hrrr 2020-10-02 21:06:00+00:00 [queued]>[22m[0m
[[34m2020-10-02 15:06:31,620[0m] {[34mscheduler_job.py:[0m1195} INFO[0m - Sending [01m('id_11', 'id_calc_pgrad_hrrr', datetime.datetime(2020, 10, 2, 21, 6, tzinfo=<Timezone [UTC]>), 1)[22m to executor with priority 1 and queue [01mdefault[22m[0m
[[34m2020-10-02 15:06:31,620[0m] {[34mbase_executor.py:[0m58} INFO[0m - Adding to queue: [01m['airflow', 'run', 'id_11', 'id_calc_pgrad_hrrr', '2020-10-02T21:06:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[[34m2020-10-02 15:06:31,621[0m] {[34msequential_executor.py:[0m54} INFO[0m - Executing command: [01m['airflow', 'run', 'id_11', 'id_calc_pgrad_hrrr', '2020-10-02T21:06:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[2020-10-02 15:06:33,023] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-10-02 15:06:33,023] {dagbag.py:417} INFO - Filling up the DagBag from /home/csmith/pgrad/airflow/dags/pgrad_dag.py
Running %s on host %s <TaskInstance: id_11.id_calc_pgrad_hrrr 2020-10-02T21:06:00+00:00 [queued]> penguin
[[34m2020-10-02 15:06:38,412[0m] {[34mscheduler_job.py:[0m1334} INFO[0m - Executor reports execution of [01mid_11[22m.[01mid_calc_pgrad_hrrr[22m execution_date=[01m2020-10-02 21:06:00+00:00[22m exited with status [01msuccess[22m for try_number 1[0m
[[34m2020-10-02 15:09:03,633[0m] {[34mscheduler_job.py:[0m963} INFO[0m - 1 tasks up for execution:
	[01m<TaskInstance: id_21.id_download_nam 2020-10-02 21:09:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 15:09:03,637[0m] {[34mscheduler_job.py:[0m997} INFO[0m - Figuring out tasks to run in Pool(name=[01mdefault_pool[22m) with 128 open slots and 1 task instances ready to be queued[0m
[[34m2020-10-02 15:09:03,638[0m] {[34mscheduler_job.py:[0m1025} INFO[0m - DAG [01mid_21[22m has 0/16 running and queued tasks[0m
[[34m2020-10-02 15:09:03,643[0m] {[34mscheduler_job.py:[0m1085} INFO[0m - Setting the following tasks to queued state:
	[01m<TaskInstance: id_21.id_download_nam 2020-10-02 21:09:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 15:09:03,794[0m] {[34mscheduler_job.py:[0m1159} INFO[0m - Setting the following 1 tasks to queued state:
	[01m<TaskInstance: id_21.id_download_nam 2020-10-02 21:09:00+00:00 [queued]>[22m[0m
[[34m2020-10-02 15:09:03,794[0m] {[34mscheduler_job.py:[0m1195} INFO[0m - Sending [01m('id_21', 'id_download_nam', datetime.datetime(2020, 10, 2, 21, 9, tzinfo=<Timezone [UTC]>), 1)[22m to executor with priority 4 and queue [01mdefault[22m[0m
[[34m2020-10-02 15:09:03,794[0m] {[34mbase_executor.py:[0m58} INFO[0m - Adding to queue: [01m['airflow', 'run', 'id_21', 'id_download_nam', '2020-10-02T21:09:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[[34m2020-10-02 15:09:03,795[0m] {[34msequential_executor.py:[0m54} INFO[0m - Executing command: [01m['airflow', 'run', 'id_21', 'id_download_nam', '2020-10-02T21:09:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[2020-10-02 15:09:05,172] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-10-02 15:09:05,172] {dagbag.py:417} INFO - Filling up the DagBag from /home/csmith/pgrad/airflow/dags/pgrad_dag.py
Running %s on host %s <TaskInstance: id_21.id_download_nam 2020-10-02T21:09:00+00:00 [queued]> penguin
[[34m2020-10-02 15:09:10,474[0m] {[34mscheduler_job.py:[0m1334} INFO[0m - Executor reports execution of [01mid_21[22m.[01mid_download_nam[22m execution_date=[01m2020-10-02 21:09:00+00:00[22m exited with status [01msuccess[22m for try_number 1[0m
[[34m2020-10-02 15:09:13,538[0m] {[34mscheduler_job.py:[0m963} INFO[0m - 1 tasks up for execution:
	[01m<TaskInstance: id_21.id_process_grib_nam 2020-10-02 21:09:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 15:09:13,543[0m] {[34mscheduler_job.py:[0m997} INFO[0m - Figuring out tasks to run in Pool(name=[01mdefault_pool[22m) with 128 open slots and 1 task instances ready to be queued[0m
[[34m2020-10-02 15:09:13,543[0m] {[34mscheduler_job.py:[0m1025} INFO[0m - DAG [01mid_21[22m has 0/16 running and queued tasks[0m
[[34m2020-10-02 15:09:13,548[0m] {[34mscheduler_job.py:[0m1085} INFO[0m - Setting the following tasks to queued state:
	[01m<TaskInstance: id_21.id_process_grib_nam 2020-10-02 21:09:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 15:09:13,591[0m] {[34mscheduler_job.py:[0m1159} INFO[0m - Setting the following 1 tasks to queued state:
	[01m<TaskInstance: id_21.id_process_grib_nam 2020-10-02 21:09:00+00:00 [queued]>[22m[0m
[[34m2020-10-02 15:09:13,592[0m] {[34mscheduler_job.py:[0m1195} INFO[0m - Sending [01m('id_21', 'id_process_grib_nam', datetime.datetime(2020, 10, 2, 21, 9, tzinfo=<Timezone [UTC]>), 1)[22m to executor with priority 3 and queue [01mdefault[22m[0m
[[34m2020-10-02 15:09:13,592[0m] {[34mbase_executor.py:[0m58} INFO[0m - Adding to queue: [01m['airflow', 'run', 'id_21', 'id_process_grib_nam', '2020-10-02T21:09:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[[34m2020-10-02 15:09:13,592[0m] {[34msequential_executor.py:[0m54} INFO[0m - Executing command: [01m['airflow', 'run', 'id_21', 'id_process_grib_nam', '2020-10-02T21:09:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[2020-10-02 15:09:14,851] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-10-02 15:09:14,851] {dagbag.py:417} INFO - Filling up the DagBag from /home/csmith/pgrad/airflow/dags/pgrad_dag.py
Running %s on host %s <TaskInstance: id_21.id_process_grib_nam 2020-10-02T21:09:00+00:00 [queued]> penguin
[[34m2020-10-02 15:09:20,116[0m] {[34mscheduler_job.py:[0m1334} INFO[0m - Executor reports execution of [01mid_21[22m.[01mid_process_grib_nam[22m execution_date=[01m2020-10-02 21:09:00+00:00[22m exited with status [01msuccess[22m for try_number 1[0m
[[34m2020-10-02 15:09:23,181[0m] {[34mscheduler_job.py:[0m963} INFO[0m - 1 tasks up for execution:
	[01m<TaskInstance: id_21.id_process_csv_nam 2020-10-02 21:09:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 15:09:23,186[0m] {[34mscheduler_job.py:[0m997} INFO[0m - Figuring out tasks to run in Pool(name=[01mdefault_pool[22m) with 128 open slots and 1 task instances ready to be queued[0m
[[34m2020-10-02 15:09:23,186[0m] {[34mscheduler_job.py:[0m1025} INFO[0m - DAG [01mid_21[22m has 0/16 running and queued tasks[0m
[[34m2020-10-02 15:09:23,191[0m] {[34mscheduler_job.py:[0m1085} INFO[0m - Setting the following tasks to queued state:
	[01m<TaskInstance: id_21.id_process_csv_nam 2020-10-02 21:09:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 15:09:23,320[0m] {[34mscheduler_job.py:[0m1159} INFO[0m - Setting the following 1 tasks to queued state:
	[01m<TaskInstance: id_21.id_process_csv_nam 2020-10-02 21:09:00+00:00 [queued]>[22m[0m
[[34m2020-10-02 15:09:23,320[0m] {[34mscheduler_job.py:[0m1195} INFO[0m - Sending [01m('id_21', 'id_process_csv_nam', datetime.datetime(2020, 10, 2, 21, 9, tzinfo=<Timezone [UTC]>), 1)[22m to executor with priority 2 and queue [01mdefault[22m[0m
[[34m2020-10-02 15:09:23,320[0m] {[34mbase_executor.py:[0m58} INFO[0m - Adding to queue: [01m['airflow', 'run', 'id_21', 'id_process_csv_nam', '2020-10-02T21:09:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[[34m2020-10-02 15:09:23,320[0m] {[34msequential_executor.py:[0m54} INFO[0m - Executing command: [01m['airflow', 'run', 'id_21', 'id_process_csv_nam', '2020-10-02T21:09:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[2020-10-02 15:09:24,611] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-10-02 15:09:24,612] {dagbag.py:417} INFO - Filling up the DagBag from /home/csmith/pgrad/airflow/dags/pgrad_dag.py
Running %s on host %s <TaskInstance: id_21.id_process_csv_nam 2020-10-02T21:09:00+00:00 [queued]> penguin
[[34m2020-10-02 15:09:29,890[0m] {[34mscheduler_job.py:[0m1334} INFO[0m - Executor reports execution of [01mid_21[22m.[01mid_process_csv_nam[22m execution_date=[01m2020-10-02 21:09:00+00:00[22m exited with status [01msuccess[22m for try_number 1[0m
[[34m2020-10-02 15:09:32,943[0m] {[34mscheduler_job.py:[0m963} INFO[0m - 1 tasks up for execution:
	[01m<TaskInstance: id_21.id_calc_pgrad_nam 2020-10-02 21:09:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 15:09:32,946[0m] {[34mscheduler_job.py:[0m997} INFO[0m - Figuring out tasks to run in Pool(name=[01mdefault_pool[22m) with 128 open slots and 1 task instances ready to be queued[0m
[[34m2020-10-02 15:09:32,946[0m] {[34mscheduler_job.py:[0m1025} INFO[0m - DAG [01mid_21[22m has 0/16 running and queued tasks[0m
[[34m2020-10-02 15:09:32,949[0m] {[34mscheduler_job.py:[0m1085} INFO[0m - Setting the following tasks to queued state:
	[01m<TaskInstance: id_21.id_calc_pgrad_nam 2020-10-02 21:09:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 15:09:32,985[0m] {[34mscheduler_job.py:[0m1159} INFO[0m - Setting the following 1 tasks to queued state:
	[01m<TaskInstance: id_21.id_calc_pgrad_nam 2020-10-02 21:09:00+00:00 [queued]>[22m[0m
[[34m2020-10-02 15:09:32,986[0m] {[34mscheduler_job.py:[0m1195} INFO[0m - Sending [01m('id_21', 'id_calc_pgrad_nam', datetime.datetime(2020, 10, 2, 21, 9, tzinfo=<Timezone [UTC]>), 1)[22m to executor with priority 1 and queue [01mdefault[22m[0m
[[34m2020-10-02 15:09:32,986[0m] {[34mbase_executor.py:[0m58} INFO[0m - Adding to queue: [01m['airflow', 'run', 'id_21', 'id_calc_pgrad_nam', '2020-10-02T21:09:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[[34m2020-10-02 15:09:32,986[0m] {[34msequential_executor.py:[0m54} INFO[0m - Executing command: [01m['airflow', 'run', 'id_21', 'id_calc_pgrad_nam', '2020-10-02T21:09:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[2020-10-02 15:09:34,242] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-10-02 15:09:34,243] {dagbag.py:417} INFO - Filling up the DagBag from /home/csmith/pgrad/airflow/dags/pgrad_dag.py
Running %s on host %s <TaskInstance: id_21.id_calc_pgrad_nam 2020-10-02T21:09:00+00:00 [queued]> penguin
[[34m2020-10-02 15:09:39,535[0m] {[34mscheduler_job.py:[0m1334} INFO[0m - Executor reports execution of [01mid_21[22m.[01mid_calc_pgrad_nam[22m execution_date=[01m2020-10-02 21:09:00+00:00[22m exited with status [01msuccess[22m for try_number 1[0m
[[34m2020-10-02 15:13:02,821[0m] {[34mscheduler_job.py:[0m963} INFO[0m - 1 tasks up for execution:
	[01m<TaskInstance: id_31.id_download_gfs 2020-10-02 21:13:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 15:13:02,825[0m] {[34mscheduler_job.py:[0m997} INFO[0m - Figuring out tasks to run in Pool(name=[01mdefault_pool[22m) with 128 open slots and 1 task instances ready to be queued[0m
[[34m2020-10-02 15:13:02,825[0m] {[34mscheduler_job.py:[0m1025} INFO[0m - DAG [01mid_31[22m has 0/16 running and queued tasks[0m
[[34m2020-10-02 15:13:02,829[0m] {[34mscheduler_job.py:[0m1085} INFO[0m - Setting the following tasks to queued state:
	[01m<TaskInstance: id_31.id_download_gfs 2020-10-02 21:13:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 15:13:02,869[0m] {[34mscheduler_job.py:[0m1159} INFO[0m - Setting the following 1 tasks to queued state:
	[01m<TaskInstance: id_31.id_download_gfs 2020-10-02 21:13:00+00:00 [queued]>[22m[0m
[[34m2020-10-02 15:13:02,869[0m] {[34mscheduler_job.py:[0m1195} INFO[0m - Sending [01m('id_31', 'id_download_gfs', datetime.datetime(2020, 10, 2, 21, 13, tzinfo=<Timezone [UTC]>), 1)[22m to executor with priority 4 and queue [01mdefault[22m[0m
[[34m2020-10-02 15:13:02,869[0m] {[34mbase_executor.py:[0m58} INFO[0m - Adding to queue: [01m['airflow', 'run', 'id_31', 'id_download_gfs', '2020-10-02T21:13:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[[34m2020-10-02 15:13:02,869[0m] {[34msequential_executor.py:[0m54} INFO[0m - Executing command: [01m['airflow', 'run', 'id_31', 'id_download_gfs', '2020-10-02T21:13:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[2020-10-02 15:13:04,108] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-10-02 15:13:04,108] {dagbag.py:417} INFO - Filling up the DagBag from /home/csmith/pgrad/airflow/dags/pgrad_dag.py
Running %s on host %s <TaskInstance: id_31.id_download_gfs 2020-10-02T21:13:00+00:00 [queued]> penguin
[[34m2020-10-02 15:15:29,577[0m] {[34mscheduler_job.py:[0m1334} INFO[0m - Executor reports execution of [01mid_31[22m.[01mid_download_gfs[22m execution_date=[01m2020-10-02 21:13:00+00:00[22m exited with status [01msuccess[22m for try_number 1[0m
[[34m2020-10-02 15:15:32,636[0m] {[34mscheduler_job.py:[0m963} INFO[0m - 1 tasks up for execution:
	[01m<TaskInstance: id_31.id_process_grib_gfs 2020-10-02 21:13:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 15:15:32,640[0m] {[34mscheduler_job.py:[0m997} INFO[0m - Figuring out tasks to run in Pool(name=[01mdefault_pool[22m) with 128 open slots and 1 task instances ready to be queued[0m
[[34m2020-10-02 15:15:32,640[0m] {[34mscheduler_job.py:[0m1025} INFO[0m - DAG [01mid_31[22m has 0/16 running and queued tasks[0m
[[34m2020-10-02 15:15:32,645[0m] {[34mscheduler_job.py:[0m1085} INFO[0m - Setting the following tasks to queued state:
	[01m<TaskInstance: id_31.id_process_grib_gfs 2020-10-02 21:13:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 15:15:32,677[0m] {[34mscheduler_job.py:[0m1159} INFO[0m - Setting the following 1 tasks to queued state:
	[01m<TaskInstance: id_31.id_process_grib_gfs 2020-10-02 21:13:00+00:00 [queued]>[22m[0m
[[34m2020-10-02 15:15:32,677[0m] {[34mscheduler_job.py:[0m1195} INFO[0m - Sending [01m('id_31', 'id_process_grib_gfs', datetime.datetime(2020, 10, 2, 21, 13, tzinfo=<Timezone [UTC]>), 1)[22m to executor with priority 3 and queue [01mdefault[22m[0m
[[34m2020-10-02 15:15:32,677[0m] {[34mbase_executor.py:[0m58} INFO[0m - Adding to queue: [01m['airflow', 'run', 'id_31', 'id_process_grib_gfs', '2020-10-02T21:13:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[[34m2020-10-02 15:15:32,677[0m] {[34msequential_executor.py:[0m54} INFO[0m - Executing command: [01m['airflow', 'run', 'id_31', 'id_process_grib_gfs', '2020-10-02T21:13:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[2020-10-02 15:15:33,919] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-10-02 15:15:33,920] {dagbag.py:417} INFO - Filling up the DagBag from /home/csmith/pgrad/airflow/dags/pgrad_dag.py
Running %s on host %s <TaskInstance: id_31.id_process_grib_gfs 2020-10-02T21:13:00+00:00 [queued]> penguin
[[34m2020-10-02 15:15:49,224[0m] {[34mscheduler_job.py:[0m1334} INFO[0m - Executor reports execution of [01mid_31[22m.[01mid_process_grib_gfs[22m execution_date=[01m2020-10-02 21:13:00+00:00[22m exited with status [01msuccess[22m for try_number 1[0m
[[34m2020-10-02 15:15:52,276[0m] {[34mscheduler_job.py:[0m963} INFO[0m - 1 tasks up for execution:
	[01m<TaskInstance: id_31.id_process_csv_gfs 2020-10-02 21:13:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 15:15:52,279[0m] {[34mscheduler_job.py:[0m997} INFO[0m - Figuring out tasks to run in Pool(name=[01mdefault_pool[22m) with 128 open slots and 1 task instances ready to be queued[0m
[[34m2020-10-02 15:15:52,280[0m] {[34mscheduler_job.py:[0m1025} INFO[0m - DAG [01mid_31[22m has 0/16 running and queued tasks[0m
[[34m2020-10-02 15:15:52,285[0m] {[34mscheduler_job.py:[0m1085} INFO[0m - Setting the following tasks to queued state:
	[01m<TaskInstance: id_31.id_process_csv_gfs 2020-10-02 21:13:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 15:15:52,324[0m] {[34mscheduler_job.py:[0m1159} INFO[0m - Setting the following 1 tasks to queued state:
	[01m<TaskInstance: id_31.id_process_csv_gfs 2020-10-02 21:13:00+00:00 [queued]>[22m[0m
[[34m2020-10-02 15:15:52,324[0m] {[34mscheduler_job.py:[0m1195} INFO[0m - Sending [01m('id_31', 'id_process_csv_gfs', datetime.datetime(2020, 10, 2, 21, 13, tzinfo=<Timezone [UTC]>), 1)[22m to executor with priority 2 and queue [01mdefault[22m[0m
[[34m2020-10-02 15:15:52,325[0m] {[34mbase_executor.py:[0m58} INFO[0m - Adding to queue: [01m['airflow', 'run', 'id_31', 'id_process_csv_gfs', '2020-10-02T21:13:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[[34m2020-10-02 15:15:52,325[0m] {[34msequential_executor.py:[0m54} INFO[0m - Executing command: [01m['airflow', 'run', 'id_31', 'id_process_csv_gfs', '2020-10-02T21:13:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[2020-10-02 15:15:53,635] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-10-02 15:15:53,636] {dagbag.py:417} INFO - Filling up the DagBag from /home/csmith/pgrad/airflow/dags/pgrad_dag.py
Running %s on host %s <TaskInstance: id_31.id_process_csv_gfs 2020-10-02T21:13:00+00:00 [queued]> penguin
[[34m2020-10-02 15:15:58,900[0m] {[34mscheduler_job.py:[0m1334} INFO[0m - Executor reports execution of [01mid_31[22m.[01mid_process_csv_gfs[22m execution_date=[01m2020-10-02 21:13:00+00:00[22m exited with status [01msuccess[22m for try_number 1[0m
[[34m2020-10-02 15:16:01,978[0m] {[34mscheduler_job.py:[0m963} INFO[0m - 1 tasks up for execution:
	[01m<TaskInstance: id_31.id_calc_pgrad_gfs 2020-10-02 21:13:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 15:16:01,983[0m] {[34mscheduler_job.py:[0m997} INFO[0m - Figuring out tasks to run in Pool(name=[01mdefault_pool[22m) with 128 open slots and 1 task instances ready to be queued[0m
[[34m2020-10-02 15:16:01,983[0m] {[34mscheduler_job.py:[0m1025} INFO[0m - DAG [01mid_31[22m has 0/16 running and queued tasks[0m
[[34m2020-10-02 15:16:01,989[0m] {[34mscheduler_job.py:[0m1085} INFO[0m - Setting the following tasks to queued state:
	[01m<TaskInstance: id_31.id_calc_pgrad_gfs 2020-10-02 21:13:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 15:16:02,036[0m] {[34mscheduler_job.py:[0m1159} INFO[0m - Setting the following 1 tasks to queued state:
	[01m<TaskInstance: id_31.id_calc_pgrad_gfs 2020-10-02 21:13:00+00:00 [queued]>[22m[0m
[[34m2020-10-02 15:16:02,036[0m] {[34mscheduler_job.py:[0m1195} INFO[0m - Sending [01m('id_31', 'id_calc_pgrad_gfs', datetime.datetime(2020, 10, 2, 21, 13, tzinfo=<Timezone [UTC]>), 1)[22m to executor with priority 1 and queue [01mdefault[22m[0m
[[34m2020-10-02 15:16:02,036[0m] {[34mbase_executor.py:[0m58} INFO[0m - Adding to queue: [01m['airflow', 'run', 'id_31', 'id_calc_pgrad_gfs', '2020-10-02T21:13:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[[34m2020-10-02 15:16:02,037[0m] {[34msequential_executor.py:[0m54} INFO[0m - Executing command: [01m['airflow', 'run', 'id_31', 'id_calc_pgrad_gfs', '2020-10-02T21:13:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[2020-10-02 15:16:03,326] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-10-02 15:16:03,327] {dagbag.py:417} INFO - Filling up the DagBag from /home/csmith/pgrad/airflow/dags/pgrad_dag.py
Running %s on host %s <TaskInstance: id_31.id_calc_pgrad_gfs 2020-10-02T21:13:00+00:00 [queued]> penguin
[[34m2020-10-02 15:16:08,701[0m] {[34mscheduler_job.py:[0m1334} INFO[0m - Executor reports execution of [01mid_31[22m.[01mid_calc_pgrad_gfs[22m execution_date=[01m2020-10-02 21:13:00+00:00[22m exited with status [01msuccess[22m for try_number 1[0m
[[34m2020-10-02 15:17:01,832[0m] {[34mscheduler_job.py:[0m963} INFO[0m - 1 tasks up for execution:
	[01m<TaskInstance: id_56.id_plot_data 2020-10-02 21:17:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 15:17:01,837[0m] {[34mscheduler_job.py:[0m997} INFO[0m - Figuring out tasks to run in Pool(name=[01mdefault_pool[22m) with 128 open slots and 1 task instances ready to be queued[0m
[[34m2020-10-02 15:17:01,838[0m] {[34mscheduler_job.py:[0m1025} INFO[0m - DAG [01mid_56[22m has 0/16 running and queued tasks[0m
[[34m2020-10-02 15:17:01,841[0m] {[34mscheduler_job.py:[0m1085} INFO[0m - Setting the following tasks to queued state:
	[01m<TaskInstance: id_56.id_plot_data 2020-10-02 21:17:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 15:17:01,873[0m] {[34mscheduler_job.py:[0m1159} INFO[0m - Setting the following 1 tasks to queued state:
	[01m<TaskInstance: id_56.id_plot_data 2020-10-02 21:17:00+00:00 [queued]>[22m[0m
[[34m2020-10-02 15:17:01,873[0m] {[34mscheduler_job.py:[0m1195} INFO[0m - Sending [01m('id_56', 'id_plot_data', datetime.datetime(2020, 10, 2, 21, 17, tzinfo=<Timezone [UTC]>), 1)[22m to executor with priority 1 and queue [01mdefault[22m[0m
[[34m2020-10-02 15:17:01,873[0m] {[34mbase_executor.py:[0m58} INFO[0m - Adding to queue: [01m['airflow', 'run', 'id_56', 'id_plot_data', '2020-10-02T21:17:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[[34m2020-10-02 15:17:01,874[0m] {[34msequential_executor.py:[0m54} INFO[0m - Executing command: [01m['airflow', 'run', 'id_56', 'id_plot_data', '2020-10-02T21:17:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[2020-10-02 15:17:03,190] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-10-02 15:17:03,190] {dagbag.py:417} INFO - Filling up the DagBag from /home/csmith/pgrad/airflow/dags/pgrad_dag.py
Running %s on host %s <TaskInstance: id_56.id_plot_data 2020-10-02T21:17:00+00:00 [queued]> penguin
[[34m2020-10-02 15:17:33,543[0m] {[34mscheduler_job.py:[0m1334} INFO[0m - Executor reports execution of [01mid_56[22m.[01mid_plot_data[22m execution_date=[01m2020-10-02 21:17:00+00:00[22m exited with status [01msuccess[22m for try_number 1[0m
[[34m2020-10-02 16:05:03,809[0m] {[34mscheduler_job.py:[0m963} INFO[0m - 1 tasks up for execution:
	[01m<TaskInstance: id_01.id_cleanup 2020-10-02 22:05:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 16:05:03,813[0m] {[34mscheduler_job.py:[0m997} INFO[0m - Figuring out tasks to run in Pool(name=[01mdefault_pool[22m) with 128 open slots and 1 task instances ready to be queued[0m
[[34m2020-10-02 16:05:03,813[0m] {[34mscheduler_job.py:[0m1025} INFO[0m - DAG [01mid_01[22m has 0/16 running and queued tasks[0m
[[34m2020-10-02 16:05:03,816[0m] {[34mscheduler_job.py:[0m1085} INFO[0m - Setting the following tasks to queued state:
	[01m<TaskInstance: id_01.id_cleanup 2020-10-02 22:05:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 16:05:03,861[0m] {[34mscheduler_job.py:[0m1159} INFO[0m - Setting the following 1 tasks to queued state:
	[01m<TaskInstance: id_01.id_cleanup 2020-10-02 22:05:00+00:00 [queued]>[22m[0m
[[34m2020-10-02 16:05:03,861[0m] {[34mscheduler_job.py:[0m1195} INFO[0m - Sending [01m('id_01', 'id_cleanup', datetime.datetime(2020, 10, 2, 22, 5, tzinfo=<Timezone [UTC]>), 1)[22m to executor with priority 1 and queue [01mdefault[22m[0m
[[34m2020-10-02 16:05:03,861[0m] {[34mbase_executor.py:[0m58} INFO[0m - Adding to queue: [01m['airflow', 'run', 'id_01', 'id_cleanup', '2020-10-02T22:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[[34m2020-10-02 16:05:03,861[0m] {[34msequential_executor.py:[0m54} INFO[0m - Executing command: [01m['airflow', 'run', 'id_01', 'id_cleanup', '2020-10-02T22:05:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[2020-10-02 16:05:05,267] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-10-02 16:05:05,268] {dagbag.py:417} INFO - Filling up the DagBag from /home/csmith/pgrad/airflow/dags/pgrad_dag.py
Running %s on host %s <TaskInstance: id_01.id_cleanup 2020-10-02T22:05:00+00:00 [queued]> penguin
[[34m2020-10-02 16:05:10,536[0m] {[34mscheduler_job.py:[0m1334} INFO[0m - Executor reports execution of [01mid_01[22m.[01mid_cleanup[22m execution_date=[01m2020-10-02 22:05:00+00:00[22m exited with status [01msuccess[22m for try_number 1[0m
[[34m2020-10-02 16:06:03,653[0m] {[34mscheduler_job.py:[0m963} INFO[0m - 1 tasks up for execution:
	[01m<TaskInstance: id_11.id_download_hrrr 2020-10-02 22:06:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 16:06:03,657[0m] {[34mscheduler_job.py:[0m997} INFO[0m - Figuring out tasks to run in Pool(name=[01mdefault_pool[22m) with 128 open slots and 1 task instances ready to be queued[0m
[[34m2020-10-02 16:06:03,657[0m] {[34mscheduler_job.py:[0m1025} INFO[0m - DAG [01mid_11[22m has 0/16 running and queued tasks[0m
[[34m2020-10-02 16:06:03,661[0m] {[34mscheduler_job.py:[0m1085} INFO[0m - Setting the following tasks to queued state:
	[01m<TaskInstance: id_11.id_download_hrrr 2020-10-02 22:06:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 16:06:03,702[0m] {[34mscheduler_job.py:[0m1159} INFO[0m - Setting the following 1 tasks to queued state:
	[01m<TaskInstance: id_11.id_download_hrrr 2020-10-02 22:06:00+00:00 [queued]>[22m[0m
[[34m2020-10-02 16:06:03,702[0m] {[34mscheduler_job.py:[0m1195} INFO[0m - Sending [01m('id_11', 'id_download_hrrr', datetime.datetime(2020, 10, 2, 22, 6, tzinfo=<Timezone [UTC]>), 1)[22m to executor with priority 4 and queue [01mdefault[22m[0m
[[34m2020-10-02 16:06:03,703[0m] {[34mbase_executor.py:[0m58} INFO[0m - Adding to queue: [01m['airflow', 'run', 'id_11', 'id_download_hrrr', '2020-10-02T22:06:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[[34m2020-10-02 16:06:03,703[0m] {[34msequential_executor.py:[0m54} INFO[0m - Executing command: [01m['airflow', 'run', 'id_11', 'id_download_hrrr', '2020-10-02T22:06:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[2020-10-02 16:06:04,847] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-10-02 16:06:04,847] {dagbag.py:417} INFO - Filling up the DagBag from /home/csmith/pgrad/airflow/dags/pgrad_dag.py
Running %s on host %s <TaskInstance: id_11.id_download_hrrr 2020-10-02T22:06:00+00:00 [queued]> penguin
[[34m2020-10-02 16:06:10,109[0m] {[34mscheduler_job.py:[0m1334} INFO[0m - Executor reports execution of [01mid_11[22m.[01mid_download_hrrr[22m execution_date=[01m2020-10-02 22:06:00+00:00[22m exited with status [01msuccess[22m for try_number 1[0m
[[34m2020-10-02 16:06:13,207[0m] {[34mscheduler_job.py:[0m963} INFO[0m - 1 tasks up for execution:
	[01m<TaskInstance: id_11.id_process_grib_hrrr 2020-10-02 22:06:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 16:06:13,212[0m] {[34mscheduler_job.py:[0m997} INFO[0m - Figuring out tasks to run in Pool(name=[01mdefault_pool[22m) with 128 open slots and 1 task instances ready to be queued[0m
[[34m2020-10-02 16:06:13,212[0m] {[34mscheduler_job.py:[0m1025} INFO[0m - DAG [01mid_11[22m has 0/16 running and queued tasks[0m
[[34m2020-10-02 16:06:13,217[0m] {[34mscheduler_job.py:[0m1085} INFO[0m - Setting the following tasks to queued state:
	[01m<TaskInstance: id_11.id_process_grib_hrrr 2020-10-02 22:06:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 16:06:13,306[0m] {[34mscheduler_job.py:[0m1159} INFO[0m - Setting the following 1 tasks to queued state:
	[01m<TaskInstance: id_11.id_process_grib_hrrr 2020-10-02 22:06:00+00:00 [queued]>[22m[0m
[[34m2020-10-02 16:06:13,306[0m] {[34mscheduler_job.py:[0m1195} INFO[0m - Sending [01m('id_11', 'id_process_grib_hrrr', datetime.datetime(2020, 10, 2, 22, 6, tzinfo=<Timezone [UTC]>), 1)[22m to executor with priority 3 and queue [01mdefault[22m[0m
[[34m2020-10-02 16:06:13,307[0m] {[34mbase_executor.py:[0m58} INFO[0m - Adding to queue: [01m['airflow', 'run', 'id_11', 'id_process_grib_hrrr', '2020-10-02T22:06:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[[34m2020-10-02 16:06:13,307[0m] {[34msequential_executor.py:[0m54} INFO[0m - Executing command: [01m['airflow', 'run', 'id_11', 'id_process_grib_hrrr', '2020-10-02T22:06:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[2020-10-02 16:06:14,736] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-10-02 16:06:14,736] {dagbag.py:417} INFO - Filling up the DagBag from /home/csmith/pgrad/airflow/dags/pgrad_dag.py
Running %s on host %s <TaskInstance: id_11.id_process_grib_hrrr 2020-10-02T22:06:00+00:00 [queued]> penguin
[[34m2020-10-02 16:06:20,045[0m] {[34mscheduler_job.py:[0m1334} INFO[0m - Executor reports execution of [01mid_11[22m.[01mid_process_grib_hrrr[22m execution_date=[01m2020-10-02 22:06:00+00:00[22m exited with status [01msuccess[22m for try_number 1[0m
[[34m2020-10-02 16:06:23,116[0m] {[34mscheduler_job.py:[0m963} INFO[0m - 1 tasks up for execution:
	[01m<TaskInstance: id_11.id_process_csv_hrrr 2020-10-02 22:06:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 16:06:23,121[0m] {[34mscheduler_job.py:[0m997} INFO[0m - Figuring out tasks to run in Pool(name=[01mdefault_pool[22m) with 128 open slots and 1 task instances ready to be queued[0m
[[34m2020-10-02 16:06:23,121[0m] {[34mscheduler_job.py:[0m1025} INFO[0m - DAG [01mid_11[22m has 0/16 running and queued tasks[0m
[[34m2020-10-02 16:06:23,127[0m] {[34mscheduler_job.py:[0m1085} INFO[0m - Setting the following tasks to queued state:
	[01m<TaskInstance: id_11.id_process_csv_hrrr 2020-10-02 22:06:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 16:06:23,240[0m] {[34mscheduler_job.py:[0m1159} INFO[0m - Setting the following 1 tasks to queued state:
	[01m<TaskInstance: id_11.id_process_csv_hrrr 2020-10-02 22:06:00+00:00 [queued]>[22m[0m
[[34m2020-10-02 16:06:23,240[0m] {[34mscheduler_job.py:[0m1195} INFO[0m - Sending [01m('id_11', 'id_process_csv_hrrr', datetime.datetime(2020, 10, 2, 22, 6, tzinfo=<Timezone [UTC]>), 1)[22m to executor with priority 2 and queue [01mdefault[22m[0m
[[34m2020-10-02 16:06:23,240[0m] {[34mbase_executor.py:[0m58} INFO[0m - Adding to queue: [01m['airflow', 'run', 'id_11', 'id_process_csv_hrrr', '2020-10-02T22:06:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[[34m2020-10-02 16:06:23,241[0m] {[34msequential_executor.py:[0m54} INFO[0m - Executing command: [01m['airflow', 'run', 'id_11', 'id_process_csv_hrrr', '2020-10-02T22:06:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[2020-10-02 16:06:24,414] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-10-02 16:06:24,415] {dagbag.py:417} INFO - Filling up the DagBag from /home/csmith/pgrad/airflow/dags/pgrad_dag.py
Running %s on host %s <TaskInstance: id_11.id_process_csv_hrrr 2020-10-02T22:06:00+00:00 [queued]> penguin
[[34m2020-10-02 16:06:29,726[0m] {[34mscheduler_job.py:[0m1334} INFO[0m - Executor reports execution of [01mid_11[22m.[01mid_process_csv_hrrr[22m execution_date=[01m2020-10-02 22:06:00+00:00[22m exited with status [01msuccess[22m for try_number 1[0m
[[34m2020-10-02 16:06:32,786[0m] {[34mscheduler_job.py:[0m963} INFO[0m - 1 tasks up for execution:
	[01m<TaskInstance: id_11.id_calc_pgrad_hrrr 2020-10-02 22:06:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 16:06:32,790[0m] {[34mscheduler_job.py:[0m997} INFO[0m - Figuring out tasks to run in Pool(name=[01mdefault_pool[22m) with 128 open slots and 1 task instances ready to be queued[0m
[[34m2020-10-02 16:06:32,791[0m] {[34mscheduler_job.py:[0m1025} INFO[0m - DAG [01mid_11[22m has 0/16 running and queued tasks[0m
[[34m2020-10-02 16:06:32,795[0m] {[34mscheduler_job.py:[0m1085} INFO[0m - Setting the following tasks to queued state:
	[01m<TaskInstance: id_11.id_calc_pgrad_hrrr 2020-10-02 22:06:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 16:06:32,829[0m] {[34mscheduler_job.py:[0m1159} INFO[0m - Setting the following 1 tasks to queued state:
	[01m<TaskInstance: id_11.id_calc_pgrad_hrrr 2020-10-02 22:06:00+00:00 [queued]>[22m[0m
[[34m2020-10-02 16:06:32,829[0m] {[34mscheduler_job.py:[0m1195} INFO[0m - Sending [01m('id_11', 'id_calc_pgrad_hrrr', datetime.datetime(2020, 10, 2, 22, 6, tzinfo=<Timezone [UTC]>), 1)[22m to executor with priority 1 and queue [01mdefault[22m[0m
[[34m2020-10-02 16:06:32,829[0m] {[34mbase_executor.py:[0m58} INFO[0m - Adding to queue: [01m['airflow', 'run', 'id_11', 'id_calc_pgrad_hrrr', '2020-10-02T22:06:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[[34m2020-10-02 16:06:32,830[0m] {[34msequential_executor.py:[0m54} INFO[0m - Executing command: [01m['airflow', 'run', 'id_11', 'id_calc_pgrad_hrrr', '2020-10-02T22:06:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[2020-10-02 16:06:33,954] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-10-02 16:06:33,955] {dagbag.py:417} INFO - Filling up the DagBag from /home/csmith/pgrad/airflow/dags/pgrad_dag.py
Running %s on host %s <TaskInstance: id_11.id_calc_pgrad_hrrr 2020-10-02T22:06:00+00:00 [queued]> penguin
[[34m2020-10-02 16:06:39,232[0m] {[34mscheduler_job.py:[0m1334} INFO[0m - Executor reports execution of [01mid_11[22m.[01mid_calc_pgrad_hrrr[22m execution_date=[01m2020-10-02 22:06:00+00:00[22m exited with status [01msuccess[22m for try_number 1[0m
[[34m2020-10-02 16:09:02,460[0m] {[34mscheduler_job.py:[0m963} INFO[0m - 1 tasks up for execution:
	[01m<TaskInstance: id_21.id_download_nam 2020-10-02 22:09:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 16:09:02,465[0m] {[34mscheduler_job.py:[0m997} INFO[0m - Figuring out tasks to run in Pool(name=[01mdefault_pool[22m) with 128 open slots and 1 task instances ready to be queued[0m
[[34m2020-10-02 16:09:02,465[0m] {[34mscheduler_job.py:[0m1025} INFO[0m - DAG [01mid_21[22m has 0/16 running and queued tasks[0m
[[34m2020-10-02 16:09:02,471[0m] {[34mscheduler_job.py:[0m1085} INFO[0m - Setting the following tasks to queued state:
	[01m<TaskInstance: id_21.id_download_nam 2020-10-02 22:09:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 16:09:02,544[0m] {[34mscheduler_job.py:[0m1159} INFO[0m - Setting the following 1 tasks to queued state:
	[01m<TaskInstance: id_21.id_download_nam 2020-10-02 22:09:00+00:00 [queued]>[22m[0m
[[34m2020-10-02 16:09:02,544[0m] {[34mscheduler_job.py:[0m1195} INFO[0m - Sending [01m('id_21', 'id_download_nam', datetime.datetime(2020, 10, 2, 22, 9, tzinfo=<Timezone [UTC]>), 1)[22m to executor with priority 4 and queue [01mdefault[22m[0m
[[34m2020-10-02 16:09:02,545[0m] {[34mbase_executor.py:[0m58} INFO[0m - Adding to queue: [01m['airflow', 'run', 'id_21', 'id_download_nam', '2020-10-02T22:09:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[[34m2020-10-02 16:09:02,545[0m] {[34msequential_executor.py:[0m54} INFO[0m - Executing command: [01m['airflow', 'run', 'id_21', 'id_download_nam', '2020-10-02T22:09:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[2020-10-02 16:09:03,780] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-10-02 16:09:03,781] {dagbag.py:417} INFO - Filling up the DagBag from /home/csmith/pgrad/airflow/dags/pgrad_dag.py
Running %s on host %s <TaskInstance: id_21.id_download_nam 2020-10-02T22:09:00+00:00 [queued]> penguin
[[34m2020-10-02 16:09:09,037[0m] {[34mscheduler_job.py:[0m1334} INFO[0m - Executor reports execution of [01mid_21[22m.[01mid_download_nam[22m execution_date=[01m2020-10-02 22:09:00+00:00[22m exited with status [01msuccess[22m for try_number 1[0m
[[34m2020-10-02 16:09:12,106[0m] {[34mscheduler_job.py:[0m963} INFO[0m - 1 tasks up for execution:
	[01m<TaskInstance: id_21.id_process_grib_nam 2020-10-02 22:09:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 16:09:12,111[0m] {[34mscheduler_job.py:[0m997} INFO[0m - Figuring out tasks to run in Pool(name=[01mdefault_pool[22m) with 128 open slots and 1 task instances ready to be queued[0m
[[34m2020-10-02 16:09:12,111[0m] {[34mscheduler_job.py:[0m1025} INFO[0m - DAG [01mid_21[22m has 0/16 running and queued tasks[0m
[[34m2020-10-02 16:09:12,117[0m] {[34mscheduler_job.py:[0m1085} INFO[0m - Setting the following tasks to queued state:
	[01m<TaskInstance: id_21.id_process_grib_nam 2020-10-02 22:09:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 16:09:12,322[0m] {[34mscheduler_job.py:[0m1159} INFO[0m - Setting the following 1 tasks to queued state:
	[01m<TaskInstance: id_21.id_process_grib_nam 2020-10-02 22:09:00+00:00 [queued]>[22m[0m
[[34m2020-10-02 16:09:12,323[0m] {[34mscheduler_job.py:[0m1195} INFO[0m - Sending [01m('id_21', 'id_process_grib_nam', datetime.datetime(2020, 10, 2, 22, 9, tzinfo=<Timezone [UTC]>), 1)[22m to executor with priority 3 and queue [01mdefault[22m[0m
[[34m2020-10-02 16:09:12,323[0m] {[34mbase_executor.py:[0m58} INFO[0m - Adding to queue: [01m['airflow', 'run', 'id_21', 'id_process_grib_nam', '2020-10-02T22:09:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[[34m2020-10-02 16:09:12,323[0m] {[34msequential_executor.py:[0m54} INFO[0m - Executing command: [01m['airflow', 'run', 'id_21', 'id_process_grib_nam', '2020-10-02T22:09:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[2020-10-02 16:09:13,491] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-10-02 16:09:13,492] {dagbag.py:417} INFO - Filling up the DagBag from /home/csmith/pgrad/airflow/dags/pgrad_dag.py
Running %s on host %s <TaskInstance: id_21.id_process_grib_nam 2020-10-02T22:09:00+00:00 [queued]> penguin
[[34m2020-10-02 16:09:18,763[0m] {[34mscheduler_job.py:[0m1334} INFO[0m - Executor reports execution of [01mid_21[22m.[01mid_process_grib_nam[22m execution_date=[01m2020-10-02 22:09:00+00:00[22m exited with status [01msuccess[22m for try_number 1[0m
[[34m2020-10-02 16:09:21,816[0m] {[34mscheduler_job.py:[0m963} INFO[0m - 1 tasks up for execution:
	[01m<TaskInstance: id_21.id_process_csv_nam 2020-10-02 22:09:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 16:09:21,818[0m] {[34mscheduler_job.py:[0m997} INFO[0m - Figuring out tasks to run in Pool(name=[01mdefault_pool[22m) with 128 open slots and 1 task instances ready to be queued[0m
[[34m2020-10-02 16:09:21,819[0m] {[34mscheduler_job.py:[0m1025} INFO[0m - DAG [01mid_21[22m has 0/16 running and queued tasks[0m
[[34m2020-10-02 16:09:21,821[0m] {[34mscheduler_job.py:[0m1085} INFO[0m - Setting the following tasks to queued state:
	[01m<TaskInstance: id_21.id_process_csv_nam 2020-10-02 22:09:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 16:09:21,857[0m] {[34mscheduler_job.py:[0m1159} INFO[0m - Setting the following 1 tasks to queued state:
	[01m<TaskInstance: id_21.id_process_csv_nam 2020-10-02 22:09:00+00:00 [queued]>[22m[0m
[[34m2020-10-02 16:09:21,858[0m] {[34mscheduler_job.py:[0m1195} INFO[0m - Sending [01m('id_21', 'id_process_csv_nam', datetime.datetime(2020, 10, 2, 22, 9, tzinfo=<Timezone [UTC]>), 1)[22m to executor with priority 2 and queue [01mdefault[22m[0m
[[34m2020-10-02 16:09:21,858[0m] {[34mbase_executor.py:[0m58} INFO[0m - Adding to queue: [01m['airflow', 'run', 'id_21', 'id_process_csv_nam', '2020-10-02T22:09:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[[34m2020-10-02 16:09:21,858[0m] {[34msequential_executor.py:[0m54} INFO[0m - Executing command: [01m['airflow', 'run', 'id_21', 'id_process_csv_nam', '2020-10-02T22:09:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[2020-10-02 16:09:23,084] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-10-02 16:09:23,085] {dagbag.py:417} INFO - Filling up the DagBag from /home/csmith/pgrad/airflow/dags/pgrad_dag.py
Running %s on host %s <TaskInstance: id_21.id_process_csv_nam 2020-10-02T22:09:00+00:00 [queued]> penguin
[[34m2020-10-02 16:09:28,421[0m] {[34mscheduler_job.py:[0m1334} INFO[0m - Executor reports execution of [01mid_21[22m.[01mid_process_csv_nam[22m execution_date=[01m2020-10-02 22:09:00+00:00[22m exited with status [01msuccess[22m for try_number 1[0m
[[34m2020-10-02 16:09:31,480[0m] {[34mscheduler_job.py:[0m963} INFO[0m - 1 tasks up for execution:
	[01m<TaskInstance: id_21.id_calc_pgrad_nam 2020-10-02 22:09:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 16:09:31,484[0m] {[34mscheduler_job.py:[0m997} INFO[0m - Figuring out tasks to run in Pool(name=[01mdefault_pool[22m) with 128 open slots and 1 task instances ready to be queued[0m
[[34m2020-10-02 16:09:31,484[0m] {[34mscheduler_job.py:[0m1025} INFO[0m - DAG [01mid_21[22m has 0/16 running and queued tasks[0m
[[34m2020-10-02 16:09:31,488[0m] {[34mscheduler_job.py:[0m1085} INFO[0m - Setting the following tasks to queued state:
	[01m<TaskInstance: id_21.id_calc_pgrad_nam 2020-10-02 22:09:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 16:09:31,528[0m] {[34mscheduler_job.py:[0m1159} INFO[0m - Setting the following 1 tasks to queued state:
	[01m<TaskInstance: id_21.id_calc_pgrad_nam 2020-10-02 22:09:00+00:00 [queued]>[22m[0m
[[34m2020-10-02 16:09:31,529[0m] {[34mscheduler_job.py:[0m1195} INFO[0m - Sending [01m('id_21', 'id_calc_pgrad_nam', datetime.datetime(2020, 10, 2, 22, 9, tzinfo=<Timezone [UTC]>), 1)[22m to executor with priority 1 and queue [01mdefault[22m[0m
[[34m2020-10-02 16:09:31,529[0m] {[34mbase_executor.py:[0m58} INFO[0m - Adding to queue: [01m['airflow', 'run', 'id_21', 'id_calc_pgrad_nam', '2020-10-02T22:09:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[[34m2020-10-02 16:09:31,529[0m] {[34msequential_executor.py:[0m54} INFO[0m - Executing command: [01m['airflow', 'run', 'id_21', 'id_calc_pgrad_nam', '2020-10-02T22:09:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[2020-10-02 16:09:32,727] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-10-02 16:09:32,728] {dagbag.py:417} INFO - Filling up the DagBag from /home/csmith/pgrad/airflow/dags/pgrad_dag.py
Running %s on host %s <TaskInstance: id_21.id_calc_pgrad_nam 2020-10-02T22:09:00+00:00 [queued]> penguin
[[34m2020-10-02 16:09:38,000[0m] {[34mscheduler_job.py:[0m1334} INFO[0m - Executor reports execution of [01mid_21[22m.[01mid_calc_pgrad_nam[22m execution_date=[01m2020-10-02 22:09:00+00:00[22m exited with status [01msuccess[22m for try_number 1[0m
[[34m2020-10-02 16:13:03,230[0m] {[34mscheduler_job.py:[0m963} INFO[0m - 1 tasks up for execution:
	[01m<TaskInstance: id_31.id_download_gfs 2020-10-02 22:13:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 16:13:03,244[0m] {[34mscheduler_job.py:[0m997} INFO[0m - Figuring out tasks to run in Pool(name=[01mdefault_pool[22m) with 128 open slots and 1 task instances ready to be queued[0m
[[34m2020-10-02 16:13:03,244[0m] {[34mscheduler_job.py:[0m1025} INFO[0m - DAG [01mid_31[22m has 0/16 running and queued tasks[0m
[[34m2020-10-02 16:13:03,268[0m] {[34mscheduler_job.py:[0m1085} INFO[0m - Setting the following tasks to queued state:
	[01m<TaskInstance: id_31.id_download_gfs 2020-10-02 22:13:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 16:13:03,399[0m] {[34mscheduler_job.py:[0m1159} INFO[0m - Setting the following 1 tasks to queued state:
	[01m<TaskInstance: id_31.id_download_gfs 2020-10-02 22:13:00+00:00 [queued]>[22m[0m
[[34m2020-10-02 16:13:03,401[0m] {[34mscheduler_job.py:[0m1195} INFO[0m - Sending [01m('id_31', 'id_download_gfs', datetime.datetime(2020, 10, 2, 22, 13, tzinfo=<Timezone [UTC]>), 1)[22m to executor with priority 4 and queue [01mdefault[22m[0m
[[34m2020-10-02 16:13:03,401[0m] {[34mbase_executor.py:[0m58} INFO[0m - Adding to queue: [01m['airflow', 'run', 'id_31', 'id_download_gfs', '2020-10-02T22:13:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[[34m2020-10-02 16:13:03,402[0m] {[34msequential_executor.py:[0m54} INFO[0m - Executing command: [01m['airflow', 'run', 'id_31', 'id_download_gfs', '2020-10-02T22:13:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[2020-10-02 16:13:06,194] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-10-02 16:13:06,194] {dagbag.py:417} INFO - Filling up the DagBag from /home/csmith/pgrad/airflow/dags/pgrad_dag.py
Running %s on host %s <TaskInstance: id_31.id_download_gfs 2020-10-02T22:13:00+00:00 [queued]> penguin
[[34m2020-10-02 16:13:41,520[0m] {[34mscheduler_job.py:[0m1334} INFO[0m - Executor reports execution of [01mid_31[22m.[01mid_download_gfs[22m execution_date=[01m2020-10-02 22:13:00+00:00[22m exited with status [01msuccess[22m for try_number 1[0m
[[34m2020-10-02 16:13:44,588[0m] {[34mscheduler_job.py:[0m963} INFO[0m - 1 tasks up for execution:
	[01m<TaskInstance: id_31.id_process_grib_gfs 2020-10-02 22:13:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 16:13:44,593[0m] {[34mscheduler_job.py:[0m997} INFO[0m - Figuring out tasks to run in Pool(name=[01mdefault_pool[22m) with 128 open slots and 1 task instances ready to be queued[0m
[[34m2020-10-02 16:13:44,594[0m] {[34mscheduler_job.py:[0m1025} INFO[0m - DAG [01mid_31[22m has 0/16 running and queued tasks[0m
[[34m2020-10-02 16:13:44,600[0m] {[34mscheduler_job.py:[0m1085} INFO[0m - Setting the following tasks to queued state:
	[01m<TaskInstance: id_31.id_process_grib_gfs 2020-10-02 22:13:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 16:13:44,757[0m] {[34mscheduler_job.py:[0m1159} INFO[0m - Setting the following 1 tasks to queued state:
	[01m<TaskInstance: id_31.id_process_grib_gfs 2020-10-02 22:13:00+00:00 [queued]>[22m[0m
[[34m2020-10-02 16:13:44,758[0m] {[34mscheduler_job.py:[0m1195} INFO[0m - Sending [01m('id_31', 'id_process_grib_gfs', datetime.datetime(2020, 10, 2, 22, 13, tzinfo=<Timezone [UTC]>), 1)[22m to executor with priority 3 and queue [01mdefault[22m[0m
[[34m2020-10-02 16:13:44,758[0m] {[34mbase_executor.py:[0m58} INFO[0m - Adding to queue: [01m['airflow', 'run', 'id_31', 'id_process_grib_gfs', '2020-10-02T22:13:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[[34m2020-10-02 16:13:44,758[0m] {[34msequential_executor.py:[0m54} INFO[0m - Executing command: [01m['airflow', 'run', 'id_31', 'id_process_grib_gfs', '2020-10-02T22:13:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[2020-10-02 16:13:45,924] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-10-02 16:13:45,924] {dagbag.py:417} INFO - Filling up the DagBag from /home/csmith/pgrad/airflow/dags/pgrad_dag.py
Running %s on host %s <TaskInstance: id_31.id_process_grib_gfs 2020-10-02T22:13:00+00:00 [queued]> penguin
[[34m2020-10-02 16:13:51,216[0m] {[34mscheduler_job.py:[0m1334} INFO[0m - Executor reports execution of [01mid_31[22m.[01mid_process_grib_gfs[22m execution_date=[01m2020-10-02 22:13:00+00:00[22m exited with status [01msuccess[22m for try_number 1[0m
[[34m2020-10-02 16:13:54,275[0m] {[34mscheduler_job.py:[0m963} INFO[0m - 1 tasks up for execution:
	[01m<TaskInstance: id_31.id_process_csv_gfs 2020-10-02 22:13:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 16:13:54,280[0m] {[34mscheduler_job.py:[0m997} INFO[0m - Figuring out tasks to run in Pool(name=[01mdefault_pool[22m) with 128 open slots and 1 task instances ready to be queued[0m
[[34m2020-10-02 16:13:54,280[0m] {[34mscheduler_job.py:[0m1025} INFO[0m - DAG [01mid_31[22m has 0/16 running and queued tasks[0m
[[34m2020-10-02 16:13:54,286[0m] {[34mscheduler_job.py:[0m1085} INFO[0m - Setting the following tasks to queued state:
	[01m<TaskInstance: id_31.id_process_csv_gfs 2020-10-02 22:13:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 16:13:54,423[0m] {[34mscheduler_job.py:[0m1159} INFO[0m - Setting the following 1 tasks to queued state:
	[01m<TaskInstance: id_31.id_process_csv_gfs 2020-10-02 22:13:00+00:00 [queued]>[22m[0m
[[34m2020-10-02 16:13:54,424[0m] {[34mscheduler_job.py:[0m1195} INFO[0m - Sending [01m('id_31', 'id_process_csv_gfs', datetime.datetime(2020, 10, 2, 22, 13, tzinfo=<Timezone [UTC]>), 1)[22m to executor with priority 2 and queue [01mdefault[22m[0m
[[34m2020-10-02 16:13:54,424[0m] {[34mbase_executor.py:[0m58} INFO[0m - Adding to queue: [01m['airflow', 'run', 'id_31', 'id_process_csv_gfs', '2020-10-02T22:13:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[[34m2020-10-02 16:13:54,424[0m] {[34msequential_executor.py:[0m54} INFO[0m - Executing command: [01m['airflow', 'run', 'id_31', 'id_process_csv_gfs', '2020-10-02T22:13:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[2020-10-02 16:13:55,592] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-10-02 16:13:55,592] {dagbag.py:417} INFO - Filling up the DagBag from /home/csmith/pgrad/airflow/dags/pgrad_dag.py
Running %s on host %s <TaskInstance: id_31.id_process_csv_gfs 2020-10-02T22:13:00+00:00 [queued]> penguin
[[34m2020-10-02 16:14:00,899[0m] {[34mscheduler_job.py:[0m1334} INFO[0m - Executor reports execution of [01mid_31[22m.[01mid_process_csv_gfs[22m execution_date=[01m2020-10-02 22:13:00+00:00[22m exited with status [01msuccess[22m for try_number 1[0m
[[34m2020-10-02 16:14:03,966[0m] {[34mscheduler_job.py:[0m963} INFO[0m - 1 tasks up for execution:
	[01m<TaskInstance: id_31.id_calc_pgrad_gfs 2020-10-02 22:13:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 16:14:03,971[0m] {[34mscheduler_job.py:[0m997} INFO[0m - Figuring out tasks to run in Pool(name=[01mdefault_pool[22m) with 128 open slots and 1 task instances ready to be queued[0m
[[34m2020-10-02 16:14:03,971[0m] {[34mscheduler_job.py:[0m1025} INFO[0m - DAG [01mid_31[22m has 0/16 running and queued tasks[0m
[[34m2020-10-02 16:14:03,975[0m] {[34mscheduler_job.py:[0m1085} INFO[0m - Setting the following tasks to queued state:
	[01m<TaskInstance: id_31.id_calc_pgrad_gfs 2020-10-02 22:13:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 16:14:04,006[0m] {[34mscheduler_job.py:[0m1159} INFO[0m - Setting the following 1 tasks to queued state:
	[01m<TaskInstance: id_31.id_calc_pgrad_gfs 2020-10-02 22:13:00+00:00 [queued]>[22m[0m
[[34m2020-10-02 16:14:04,006[0m] {[34mscheduler_job.py:[0m1195} INFO[0m - Sending [01m('id_31', 'id_calc_pgrad_gfs', datetime.datetime(2020, 10, 2, 22, 13, tzinfo=<Timezone [UTC]>), 1)[22m to executor with priority 1 and queue [01mdefault[22m[0m
[[34m2020-10-02 16:14:04,007[0m] {[34mbase_executor.py:[0m58} INFO[0m - Adding to queue: [01m['airflow', 'run', 'id_31', 'id_calc_pgrad_gfs', '2020-10-02T22:13:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[[34m2020-10-02 16:14:04,007[0m] {[34msequential_executor.py:[0m54} INFO[0m - Executing command: [01m['airflow', 'run', 'id_31', 'id_calc_pgrad_gfs', '2020-10-02T22:13:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[2020-10-02 16:14:05,526] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-10-02 16:14:05,527] {dagbag.py:417} INFO - Filling up the DagBag from /home/csmith/pgrad/airflow/dags/pgrad_dag.py
Running %s on host %s <TaskInstance: id_31.id_calc_pgrad_gfs 2020-10-02T22:13:00+00:00 [queued]> penguin
[[34m2020-10-02 16:14:10,806[0m] {[34mscheduler_job.py:[0m1334} INFO[0m - Executor reports execution of [01mid_31[22m.[01mid_calc_pgrad_gfs[22m execution_date=[01m2020-10-02 22:13:00+00:00[22m exited with status [01msuccess[22m for try_number 1[0m
[[34m2020-10-02 16:17:02,061[0m] {[34mscheduler_job.py:[0m963} INFO[0m - 1 tasks up for execution:
	[01m<TaskInstance: id_56.id_plot_data 2020-10-02 22:17:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 16:17:02,066[0m] {[34mscheduler_job.py:[0m997} INFO[0m - Figuring out tasks to run in Pool(name=[01mdefault_pool[22m) with 128 open slots and 1 task instances ready to be queued[0m
[[34m2020-10-02 16:17:02,066[0m] {[34mscheduler_job.py:[0m1025} INFO[0m - DAG [01mid_56[22m has 0/16 running and queued tasks[0m
[[34m2020-10-02 16:17:02,072[0m] {[34mscheduler_job.py:[0m1085} INFO[0m - Setting the following tasks to queued state:
	[01m<TaskInstance: id_56.id_plot_data 2020-10-02 22:17:00+00:00 [scheduled]>[22m[0m
[[34m2020-10-02 16:17:02,139[0m] {[34mscheduler_job.py:[0m1159} INFO[0m - Setting the following 1 tasks to queued state:
	[01m<TaskInstance: id_56.id_plot_data 2020-10-02 22:17:00+00:00 [queued]>[22m[0m
[[34m2020-10-02 16:17:02,140[0m] {[34mscheduler_job.py:[0m1195} INFO[0m - Sending [01m('id_56', 'id_plot_data', datetime.datetime(2020, 10, 2, 22, 17, tzinfo=<Timezone [UTC]>), 1)[22m to executor with priority 1 and queue [01mdefault[22m[0m
[[34m2020-10-02 16:17:02,140[0m] {[34mbase_executor.py:[0m58} INFO[0m - Adding to queue: [01m['airflow', 'run', 'id_56', 'id_plot_data', '2020-10-02T22:17:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[[34m2020-10-02 16:17:02,140[0m] {[34msequential_executor.py:[0m54} INFO[0m - Executing command: [01m['airflow', 'run', 'id_56', 'id_plot_data', '2020-10-02T22:17:00+00:00', '--local', '--pool', 'default_pool', '-sd', '/home/csmith/pgrad/airflow/dags/pgrad_dag.py'][22m[0m
[2020-10-02 16:17:03,296] {__init__.py:50} INFO - Using executor SequentialExecutor
[2020-10-02 16:17:03,296] {dagbag.py:417} INFO - Filling up the DagBag from /home/csmith/pgrad/airflow/dags/pgrad_dag.py
Running %s on host %s <TaskInstance: id_56.id_plot_data 2020-10-02T22:17:00+00:00 [queued]> penguin
[[34m2020-10-02 16:17:33,646[0m] {[34mscheduler_job.py:[0m1334} INFO[0m - Executor reports execution of [01mid_56[22m.[01mid_plot_data[22m execution_date=[01m2020-10-02 22:17:00+00:00[22m exited with status [01msuccess[22m for try_number 1[0m
